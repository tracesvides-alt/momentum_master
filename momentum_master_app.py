import streamlit as st
import yfinance as yf
from deep_translator import GoogleTranslator
import time
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import requests
from io import StringIO
import random
from datetime import datetime, date
import plotly.express as px
import plotly.graph_objects as go
import re
import pickle
import os
import json
from deep_translator import GoogleTranslator
from newspaper import Article, Config
import nltk

# Ensure NLTK data is available
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    nltk.download('punkt', quiet=True)
    nltk.download('punkt_tab', quiet=True)

@st.cache_data(show_spinner=False, ttl=86400)
def get_article_summary(url):
    """
    Downloads article content using newspaper3k, extracts summary via NLP,
    and translates it to Japanese.
    """
    try:
        if not url or url == "#": return None
        
        # Optimization
        config = Config()
        config.fetch_images = False
        config.request_timeout = 10
        
        article = Article(url, config=config)
        article.download()
        article.parse()
        article.nlp()
        
        original_summary = article.summary
        if not original_summary:
            return "No summary could be extracted from this article."
            
        # --- Cleaning Promotional/Clickbait Text ---
        # Yahoo Finance/Motley Fool often append these.
        import re
        
        # Phrases to identify likely promotional sentences
        bad_patterns = [
            r"See also", r"Read also", r"Read next", 
            r"free report", r"Click here", r"Motley Fool",
            r"Zacks Rank", r"Insider Monkey", r"investing.com",
            r"stocks to buy", r"Top 10 stocks", r"Should you invest",
            r"Story continues", r"Advertisement",
            r"higher return potential", r"limited downside risk", 
            r"acknowledge the potential .* but", r"better buy",
            r"conviction buy", r"Top Stock to Buy", r"Five Stocks"
        ]
        
        # Split into sentences (simple split by newline or period space)
        # newspaper3k summary is usually paragraph text.
        # We'll split by newlines first, then maybe sentence boundary? 
        # Simpler approaches first: Remove lines containing bad patterns.
        
        cleaned_lines = []
        for line in original_summary.split('\n'):
            # Check sentence level cleaning if needed, but often these are separate paragraphs/lines in summary
            if any(re.search(pat, line, re.IGNORECASE) for pat in bad_patterns):
                continue
            cleaned_lines.append(line)
            
        original_summary = "\n".join(cleaned_lines)
            
        # Translate
        # Truncate if extremely long to avoid timeout/limits
        if len(original_summary) > 4000:
            original_summary = original_summary[:4000]
            
        translated = GoogleTranslator(source='auto', target='ja').translate(original_summary)
        return translated
        
    except Exception as e:
        return f"Summary failed: {str(e)}"

import market_logic
import importlib
importlib.reload(market_logic)
from market_logic import SECTOR_DEFINITIONS, TICKER_TO_SECTOR, STATIC_MOMENTUM_WATCHLIST, THEMATIC_ETFS, get_ai_stock_picks, SECTOR_TO_ETF

# --- Risk Management Helpers ---
def get_ticker_news(ticker, company_name=None):
    """
    Fetches top 3 news.
    Filters:
    1. Valid Title (Not empty)
    2. Recency (< 3 days)
    3. Relevance (Title must contain Ticker or Company Name)
    """
    try:
        news = yf.Ticker(ticker).news
        if not news: return []
        
        results = []
        now = datetime.now()
        
        # Prepare Regex for Ticker (Case-insensitive word boundary? No, Ticker usually CAPS, but let's be flexible)
        # Actually for Ticker, Case Sensitive is safer for short ones like 'BE' vs 'be'.
        # But some titles might lower case? "Bloom Energy (be) ..." Unlikely.
        # Let's simple check: 
        # 1. Ticker (Case Sensitive) in Title (Word Bound)
        # 2. Company Name (First Word) in Title (Case Insensitive)
        
        patterns = [r'\b{}\b'.format(re.escape(ticker))] # Exact Ticker Match
        
        if company_name:
            # Clean name: "Bloom Energy Corporation" -> "Bloom"
            # "NVIDIA Corp" -> "NVIDIA"
            # "Advanced Micro Devices" -> "Advanced" (Risk? "Advanced" is common word)
            # Maybe use full string up to common suffixes?
            
            # Simple heuristic: Split by space
            parts = company_name.split()
            if parts:
                main_name = parts[0]
                # If short basic word, maybe skip? But let's trust it for now.
                # Avoid very short words if they are not the ticker
                if len(main_name) > 2:
                    patterns.append(r'\b{}\b'.format(re.escape(main_name)))
                
                # Also try full name string (e.g. "Bloom Energy")
                if len(parts) > 1:
                     patterns.append(re.escape(company_name))

        for n in news:
            # 1. Normalize Logic
            content = n.get('content', n)
            title = content.get('title', '')
            
            if not title or title == "No Title":
                continue

            # --- SUBJECT FILTER ---
            # Check if any pattern matches title
            is_relevant = False
            for pat in patterns:
                if re.search(pat, title, re.IGNORECASE):
                    is_relevant = True
                    break
            
            if not is_relevant:
                # Debug print? No.
                continue
            # ----------------------

            # 2. Time Extraction
            pub_time = None
            if 'pubDate' in content:
                try:
                    ts_str = content['pubDate'].replace('Z', '')
                    pub_time = datetime.fromisoformat(ts_str)
                except: pass
            
            if not pub_time and 'providerPublishTime' in n:
                try:
                    pub_time = datetime.fromtimestamp(n['providerPublishTime'])
                except: pass
                    
            if not pub_time:
                pub_time = now # Skip if unknown? Or assume recent?
                # Let's skip to be strict
                continue

            # 3. Filter: Within 3 days
            if (now - pub_time).days > 3:
                continue

            dt = pub_time.strftime('%Y-%m-%d %H:%M')
            
            # 4. Link Extraction
            link = content.get('clickThroughUrl')
            if not link:
                link = content.get('link')
                if isinstance(link, dict): link = link.get('url')
                
            if not link: link = "#"

            results.append({
                'title': title,
                'publisher': content.get('publisher', 'Unknown'),
                'link': link,
                'time': dt
            })
            
            if len(results) >= 3:
                break
                
        return results
    except Exception as e:
        return []
STATIC_MENU_ITEMS = [
    "--- ğŸŒ æŒ‡æ•°ãƒ»ç‚ºæ›¿ãƒ»å‚µåˆ¸ (Indices/Forex/Bonds) ---",
    'USDJPY=X', '^TNX', 'BTC-USD', 'GLD',
    "--- ğŸ’» ç±³å›½æ ªï¼šAIãƒ»ãƒã‚¤ãƒ†ã‚¯ (US Tech/AI) ---",
    'NVDA', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'AAPL', 'META', 'AMD', 'PLTR', 'AVGO',
    "--- ğŸ“Š ç±³å›½ETFï¼šã‚»ã‚¯ã‚¿ãƒ¼ (US Sector ETFs) ---",
    'QQQ', 'SPY', 'SMH', 'VGT', 'XLV', 'XLP', 'XLE', 'XLF',
    "--- ğŸš€ ãƒ†ãƒ¼ãƒåˆ¥ETF (Thematic ETFs) ---",
    'URA', 'COPX', 'QTUM', 'ARKX', 'NLR'
]

# ... (rest of constants stays same until end of lists) ...

# --- Constants (Imported from market_logic) ---
# SECTOR_DEFINITIONS, TICKER_TO_SECTOR, STATIC_MOMENTUM_WATCHLIST are imported.

# --- Thematic ETF List (Metrics Benchmark) ---

# --- Thematic ETFs (Imported from market_logic) ---
# THEMATIC_ETFS is imported.

# --- Risk Management Helpers ---
def get_earnings_next(ticker):
    """
    Fetches the next earnings date.
    Returns: formatted string (e.g., 'âš ï¸ In 3 days' or '2025-10-30') or '-'
    """
    try:
        t = yf.Ticker(ticker)
        cal = t.calendar
        
        # Handle dictionary return (newer yfinance)
        if isinstance(cal, dict):
            # Key varies: 'Earnings Date' or 'Earnings High' etc.
            # Usually 'Earnings Date' is a list of dates
            dates = cal.get('Earnings Date', [])
            if not dates:
                return "-"
            next_date = dates[0] # Take the first one
        
        # Handle DataFrame return (older yfinance)
        elif isinstance(cal, pd.DataFrame):
            if cal.empty: return "-"
            # Often index is 0, 1... and columns are dates
            # Or formatted differently. Let's try to grab the first date available.
            # This part is tricky without exact dataframe structure from recent fix, 
            # but usually it finds 'Earnings Date' in dict form now.
            return "-" 
        else:
            return "-"

        # Calculate days until
        if isinstance(next_date, (datetime, date)):
            d = next_date.date() if isinstance(next_date, datetime) else next_date
            today = date.today()
            delta = (d - today).days
            
            if 0 <= delta <= 7:
                return f"âš ï¸ In {delta} days"
            elif delta < 0:
                # Past earnings (sometimes API returns previous)
                return "-"
            else:
                return d.strftime("%Y-%m-%d")
        return "-"
    except:
        return "-"

def get_ticker_news(ticker, company_name=None):
    """
    Fetches top 3 news.
    Filters:
    1. Valid Title (Not empty)
    2. Recency (< 3 days)
    3. Relevance (Title must contain Ticker or Company Name)
    """
    try:
        news = yf.Ticker(ticker).news
        if not news: return []
        
        results = []
        now = datetime.now()
        
        # Prepare Regex for Ticker (Case-insensitive word boundary? No, Ticker usually CAPS, but let's be flexible)
        # Actually for Ticker, Case Sensitive is safer for short ones like 'BE' vs 'be'.
        # But some titles might lower case? "Bloom Energy (be) ..." Unlikely.
        # Let's simple check: 
        # 1. Ticker (Case Sensitive) in Title (Word Bound)
        # 2. Company Name (First Word) in Title (Case Insensitive)
        
        patterns = [r'\b{}\b'.format(re.escape(ticker))] # Exact Ticker Match
        
        if company_name:
            # Clean name: "Bloom Energy Corporation" -> "Bloom"
            # "NVIDIA Corp" -> "NVIDIA"
            # "Advanced Micro Devices" -> "Advanced" (Risk? "Advanced" is common word)
            # Maybe use full string up to common suffixes?
            
            # Simple heuristic: Split by space
            parts = company_name.split()
            if parts:
                main_name = parts[0]
                # If short basic word, maybe skip? But let's trust it for now.
                # Avoid very short words if they are not the ticker
                if len(main_name) > 2:
                    patterns.append(r'\b{}\b'.format(re.escape(main_name)))
                
                # Also try full name string (e.g. "Bloom Energy")
                if len(parts) > 1:
                     patterns.append(re.escape(company_name))

        # --- FILTER & SORT CONFIG ---
        CATALYST_KEYWORDS = [
            r"Earnings", r"Revenue", r"EPS", r"Guidance", r"Results", r"Report",
            r"Acquisition", r"Merger", r"Deal", r"Partnership", r"Contract", r"Agreement",
            r"FDA", r"Approval", r"Trial", r"Launch", r"Announce", r"Unveil",
            r"CEO", r"CFO", r"Appoint", r"Resign", r"Management",
            r"Lawsuit", r"Settlement", r"Investigation",
            r"Upgrade", r"Downgrade"
        ]
        
        NOISE_KEYWORDS = [
            r"Implied Volatility", r"Options", r"Relative Strength", r"Technical Analysis",
            r"Zacks Rank", r"Motley Fool Stock Pick", r"Short Interest",
            r"Why .* is Moving", r"Why .* is Up", r"Why .* is Down",
            r"Stock Alert", r"Prediction", r"Forecast",
            r"ETF", r"Mutual Fund", r"Insiders are Selling", r"Insiders are Buying",
            r"Stock Market Today", r"Here is what happened"
        ]

        scored_candidates = []

        for n in news:
            # 1. Normalize Logic (Handle New vs Old API)
            content = n.get('content', n) # Fallback to n if content missing
            
            title = content.get('title', '')
            if not title or title == "No Title":
                continue

            # --- SUBJECT FILTER (RELEVANCE) ---
            is_relevant = False
            for pat in patterns:
                if re.search(pat, title, re.IGNORECASE):
                    is_relevant = True
                    break
            
            if not is_relevant:
                continue

            # 2. Time Extraction
            pub_time = None
            if 'pubDate' in content:
                try:
                    ts_str = content['pubDate'].replace('Z', '')
                    pub_time = datetime.fromisoformat(ts_str)
                except: pass
            
            if not pub_time and 'providerPublishTime' in n:
                try:
                    pub_time = datetime.fromtimestamp(n['providerPublishTime'])
                except: pass
                    
            if not pub_time:
                continue

            # 3. Filter: Within 3 days
            days_diff = (now - pub_time).days
            if days_diff > 3:
                continue
            
            dt_str = pub_time.strftime('%Y-%m-%d %H:%M')

            # --- SCORING LOGIC ---
            score = 0
            
            # Catalyst Check (+5)
            for pat in CATALYST_KEYWORDS:
                if re.search(pat, title, re.IGNORECASE):
                    score += 5
                    break
                
            # Noise Check (-10)
            for pat in NOISE_KEYWORDS:
                if re.search(pat, title, re.IGNORECASE):
                    score -= 10
                    break
            
            # Provider Check
            provider = content.get('publisher', 'Unknown')
            # Penalize known noise providers slightly if not already caught
            if 'Zacks' in provider or 'Fool' in provider:
                score -= 2

            # 4. Link Extraction
            link = content.get('clickThroughUrl')
            if not link: link = content.get('link') 
            if isinstance(link, dict): link = link.get('url')
            if not link: link = "#"
            
            scored_candidates.append({
                'title': title, # English Title for now
                'publisher': provider, 
                'link': link,
                'time': dt_str,
                'raw_time': pub_time,
                'score': score,
                'summary': content.get('summary', '') or content.get('description', '')
            })

        # --- SORTING & SELECTION ---
        # Sort by: Score (Desc) -> Time (Desc, newest first)
        scored_candidates.sort(key=lambda x: (x['score'], x['raw_time']), reverse=True)
        
        # Take Top 3
        top_results = scored_candidates[:3]
        
        results = []
        for res in top_results:
            title = res['title']
            # 5. Translation (EN -> JA)
            try:
                # Simple check: if title contains mostly ascii, assume English
                if len(title) > 0 and ord(title[0]) < 128:
                    translated_title = GoogleTranslator(source='auto', target='ja').translate(title)
                    display_title = translated_title
                    
                    # Also translate summary if exists
                    raw_summary = res['summary']
                    if raw_summary and len(raw_summary) > 20: 
                        trunc_summary = raw_summary[:300]
                        translated_summary = GoogleTranslator(source='auto', target='ja').translate(trunc_summary)
                        translated_summary += "..." if len(raw_summary) > 300 else ""
                    else:
                        translated_summary = ""
                else:
                    display_title = title
                    translated_summary = res['summary']
            except Exception as e:
                # print(f"Translation failed: {e}")
                display_title = title 
                translated_summary = ""

            # Skip if title is empty after translation
            if not display_title or display_title.strip() == '':
                continue

            results.append({
                'title': display_title,
                'original_title': title,
                'publisher': res['publisher'], 
                'link': res['link'],
                'time': res['time'],
                'summary': translated_summary
            })

        return results
    except Exception as e:
        # print(f"News Error: {e}") 
        return []

# --- Logic Functions: Shared / Correlation (Existing) ---
def get_data(tickers, period):
    # Parse tickers
    if isinstance(tickers, list):
        ticker_list = [t.strip() for t in tickers if t.strip()]
    else:
        # Fallback for string input
        ticker_list = [t.strip() for t in tickers.split(',') if t.strip()]
        
    if not ticker_list:
        return None
    
    try:
        data_frames = []
        for t in ticker_list:
            if t.startswith('---'): continue # Skip separators just in case
            try:
                # Fetch one by one to avoid bulk download header/cache issues
                df = yf.download(t, period=period, auto_adjust=True, progress=False)
                
                # Check if data is empty
                if df is None or df.empty:
                    continue
                    
                # Standardize column to Ticker name
                if isinstance(df, pd.DataFrame):
                    # Should have 'Close'
                    if 'Close' in df.columns:
                        df = df[['Close']]
                    
                    # Force rename columns to simple string ticker
                    df.columns = [t]
                
                data_frames.append(df)
            except Exception as e:
                st.warning(f"Failed to fetch {t}: {e}")
                continue

        if not data_frames:
            return None

        # Concatenate all
        data = pd.concat(data_frames, axis=1)
        
        # Align data: Forward fill to handle mismatching trading days
        data = data.ffill()
        
        # Drop only if data is still missing (e.g. leading NaNs)
        aligned_data = data.dropna()
        
        return aligned_data
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def calculate_stats(df_prices):
    """
    Calculates daily returns, correlation matrix, and cumulative returns.
    """
    if df_prices is None or df_prices.empty:
        return None, None, None
        
    # 1. Daily Returns (for Correlation)
    returns = df_prices.pct_change().dropna()
    
    # 2. Correlation Matrix
    corr_matrix = returns.corr()
    
    # 3. Cumulative Returns (for Performance Chart)
    # Rebase to 0%
    cumulative_returns = (df_prices / df_prices.iloc[0]) - 1
    
    return returns, corr_matrix, cumulative_returns

@st.cache_data(ttl=3600)
def get_dynamic_trending_tickers():
    """
    Fetches 'Most Active' tickers from Yahoo Finance.
    Existing logic for Correlation Radar default items.
    """
    fallback_tickers = ['RKLB', 'MU', 'OKLO', 'LLY', 'SOFI']
    url = "https://finance.yahoo.com/most-active"
    
    # Create exclusion set from static menu
    exclusion_set = {t for t in STATIC_MENU_ITEMS if not t.startswith('---')}
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        dfs = pd.read_html(StringIO(response.text))
        
        if dfs:
            df_scrape = dfs[0]
            if 'Symbol' in df_scrape.columns:
                candidates_raw = df_scrape['Symbol'].head(30).dropna().astype(str).tolist()
                candidates = [t.split()[0] for t in candidates_raw if t]

                # Quick filtering logic (simplified from original for brevity)
                filtered = [t for t in candidates if t not in exclusion_set]
                return filtered[:5]

        return fallback_tickers
        
    except Exception as e:
        print(f"Failed to fetch trending tickers: {e}")
        return fallback_tickers

def generate_insights(corr_matrix):
    insights = []
    
    # Define Asset Classes for Fake Hedge Detection
    defensive_assets = {'GLD', 'IAU', 'TLT', 'IEF', 'AGG', 'BND', 'XLP', 'XLV', 'XLU', 'LQD', 'USDJPY=X'}
    risky_assets = {'QQQ', 'TQQQ', 'NVDA', 'SOXL', 'SMH', 'BTC-USD', 'ETH-USD', 'MSTR', 'COIN', 'PLTR', 'TSLA', 'ARKK', 'SPY'}

    # 1. Pairwise checks
    processed_pairs = set()
    columns = corr_matrix.columns
    
    for i in range(len(columns)):
        for j in range(i+1, len(columns)):
            ticker_a = columns[i]
            ticker_b = columns[j]
            val = corr_matrix.iloc[i, j]
            
            pair_key = tuple(sorted((ticker_a, ticker_b)))
            if pair_key in processed_pairs:
                continue
            processed_pairs.add(pair_key)
            
            # Condition: Fake Hedge Detection (Priority)
            is_def_a = ticker_a in defensive_assets
            is_risk_a = ticker_a in risky_assets
            is_def_b = ticker_b in defensive_assets
            is_risk_b = ticker_b in risky_assets
            
            if (is_def_a and is_risk_b) or (is_risk_a and is_def_b):
                if val >= 0.5:
                    def_name = ticker_a if is_def_a else ticker_b
                    risk_name = ticker_b if is_def_a else ticker_a
                    
                    insights.append({
                        "type": "fake_hedge",
                        "display": f"ğŸš¨ **ãƒ˜ãƒƒã‚¸æ©Ÿèƒ½ä¸å…¨**: {def_name} ã¨ {risk_name} (ç›¸é–¢: {val:.2f})",
                        "message": f"å®‰å…¨è³‡ç”£ã¨ã•ã‚Œã‚‹ {def_name} ãŒã€ãƒªã‚¹ã‚¯è³‡ç”£ {risk_name} ã¨å¼·ãé€£å‹•ã—ã¦ã„ã¾ã™ã€‚æš´è½æ™‚ã«ã‚¯ãƒƒã‚·ãƒ§ãƒ³ã®å½¹å‰²ã‚’æœãŸã•ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                        "score": abs(val) + 0.5
                    })

            # Condition A: High Correlation
            if val > 0.7:
                insights.append({
                    "type": "risk",
                    "display": f"âš ï¸ **é›†ä¸­ãƒªã‚¹ã‚¯è­¦å‘Š**: {ticker_a} ã¨ {ticker_b} (ç›¸é–¢: {val:.2f})",
                    "message": "ã“ã®2ã¤ã¯éå¸¸ã«ä¼¼ãŸå‹•ãã‚’ã—ã¦ã„ã¾ã™ã€‚åˆ†æ•£åŠ¹æœãŒä½ã„ãŸã‚ã€ãƒã‚¸ã‚·ãƒ§ãƒ³èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                    "score": abs(val)
                })
            
            # Condition B: Inverse Correlation
            elif val < -0.3:
                insights.append({
                    "type": "hedge",
                    "display": f"ğŸ›¡ï¸ **ãƒ˜ãƒƒã‚¸æ©Ÿèƒ½**: {ticker_a} ã¨ {ticker_b} (ç›¸é–¢: {val:.2f})",
                    "message": "é€†ã®å‹•ãã‚’ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒªã‚¹ã‚¯ä½æ¸›ã«å½¹ç«‹ã£ã¦ã„ã¾ã™ã€‚",
                    "score": abs(val)
                })

    # 2. Individual Asset check (Independence)
    for ticker in columns:
        encounters = corr_matrix[ticker].drop(ticker)
        max_corr = encounters.abs().max()
        if max_corr < 0.25:
             insights.append({
                "type": "independent",
                "display": f"ğŸ§˜ **ç‹¬ç«‹ç‹¬æ­©**: {ticker}",
                "message": f"ä»–ã®è³‡ç”£ã¨ã®é€£å‹•æ€§ãŒä½ãï¼ˆæœ€å¤§ç›¸é–¢ {max_corr:.2f}ï¼‰ã€ç‹¬è‡ªã®è¦å› ã§å‹•ã„ã¦ã„ã¾ã™ã€‚åˆ†æ•£æŠ•è³‡ã®è¦³ç‚¹ã§å„ªç§€ã§ã™ã€‚",
                "score": (1 - max_corr)
            })



    # --- Filtering Logic: Max 2 per Type ---
    # Sort by score descending to keep the "most important" ones
    insights.sort(key=lambda x: x.get('score', 0), reverse=True)
    
    final_insights = []
    type_counts = {}
    
    for item in insights:
        t = item['type']
        count = type_counts.get(t, 0)
        
        if count < 2:
            final_insights.append(item)
            type_counts[t] = count + 1
            
    return final_insights

# --- Portfolio Logic (New) ---
def generate_ai_portfolios(df_sorted, corr_matrix, exclude_tickers=None):
    """
    Generates 3 Portfolio Models based on momentum & logic.
    Returns dict: {'Hunter': [...], 'Fortress': [...], 'Bento': [...]}
    Each item is dict: {Ticker, Price, Weight, LatestReturn}
    """
    portfolios = {}
    
    # Pre-filter exclusions (Short-term losers)
    if exclude_tickers:
        # Filter out excluded tickers from potential candidates
        pool = df_sorted[~df_sorted['Ticker'].isin(exclude_tickers)].copy()
    else:
        pool = df_sorted.copy()
    
    # --- Model A: ğŸ¯ The Hunter (Aggressive) ---
    # Top 5 by 1mo, RVOL > 1.2
    hunter_pool = pool[pool['RVOL'] > 1.2].copy()
    hunter_pool = hunter_pool.sort_values(by='1mo', ascending=False).head(5)
    
    if len(hunter_pool) < 5:
        # Fallback: Just top 1mo if not enough RVOL
        fallback = pool.sort_values(by='1mo', ascending=False).head(5)
        hunter_pool = fallback 
        
    portfolios['Hunter'] = hunter_pool
    
    # --- Model B: ğŸ° The Fortress (Consistent) ---
    # 3mo, 6mo, YTD all > 0. Sort by 3mo. Top 8.
    fortress_pool = pool[
        (pool['3mo'] > 0) & 
        (pool['6mo'] > 0) & 
        (pool['YTD'] > 0)
    ].copy()
    fortress_pool = fortress_pool.sort_values(by='3mo', ascending=False).head(8)
    
    if len(fortress_pool) < 5:
         # Fallback: Just top 3mo positive
         fortress_pool = pool[pool['3mo'] > 0].sort_values(by='3mo', ascending=False).head(8)
         
    portfolios['Fortress'] = fortress_pool
    
    
    # --- Model C: ğŸ¥— The Bento Box (Diversified) ---
    # Pick Top 1 (by 1mo) from each Core Sector
    # Core Sectors defined in SECTOR_DEFINITIONS keys or simplified logic
    # Keys mappings based on SECTOR_DEFINITIONS
    
    # ... (Bento logic handled in next block, just inserting Sniper before or after? 
    # Let's insert Sniper BEFORE Bento to keep alphabetical or logic flow)
    # Actually user asked for "4th portfolio". I'll put it after Bento or before. 
    # Let's put it as Model D.
    
    # --- Model D: ğŸ¦… The Sniper (Precision) ---
    # Like Hunter, but strictly NO Overheating (RSI < 70).
    # Ideal entry point: High Momentum + Volume + But not yet Overbought.
    # Base criteria: RSI < 70 AND 1mo > 0 (Must be rising)
    
    # 1. Strict: RVOL > 1.2
    sniper_pool = pool[
        (pool['RVOL'] > 1.2) & 
        (pool['RSI'] < 70) &
        (pool['1mo'] > 0)
    ].copy()
    
    # 2. Fallback if empty: Relax RVOL
    if len(sniper_pool) < 3:
        fallback_pool = pool[
            (pool['RSI'] < 70) &
            (pool['1mo'] > 0)
        ].copy()
        # Sort by 1mo to get "Strongest among non-overheated"
        sniper_pool = fallback_pool
    
    sniper_pool = sniper_pool.sort_values(by='1mo', ascending=False).head(5)
    
    portfolios['Sniper'] = sniper_pool

    # --- Model C: ğŸ¥— The Bento Box (Diversified) ---
    
    # 1. Map Tickers to Broad Category
    # We already have TICKER_TO_SECTOR
    # Broad Categories:
    # 1. AI/Semi ("ğŸ§  AI & Semi")
    # 2. Energy ("âš›ï¸ Energy & Resources")
    # 3. FinTech/Crypto ("ğŸ¦ FinTech & Real Estate")
    # 4. Space/Defense ("ğŸŒŒ Space & Defense")
    # 5. Consumer/Bio ("ğŸ’Š Consumer & Health", "ğŸš— Auto & EV")
    
    bento_picks = []
    
    # Define Target Groups (Regex friendly or exact match)
    target_groups = [
        ["AI", "Semi"], 
        ["Energy", "Resources", "Infra"],
        ["FinTech", "Crypto"],
        ["Space", "Defense"],
        ["Consumer", "Health", "Auto"]
    ]
    
    used_tickers = set()
    
    for keywords in target_groups:
        # Filter df for tickers in this sector
        candidates = []
        for t in pool['Ticker']:
            sec = TICKER_TO_SECTOR.get(t, "")
            if any(k in sec for k in keywords):
                candidates.append(t)
                
        # Get subset
        subset = pool[pool['Ticker'].isin(candidates)].sort_values(by='1mo', ascending=False)
        
        # Pick best not already satisfying correlation check?
        # Simplified: Just pick Top 1 for now, correlation check is bonus
        if not subset.empty:
            pick = subset.iloc[0]
            bento_picks.append(pick)
            used_tickers.add(pick['Ticker'])
    
    # Check if we have 5?
    if len(bento_picks) < 5:
        # Fill with "Independent" stocks if missing sectors
        # Find low correlation stocks
        pass # Keep what we have
        
    portfolios['Bento'] = pd.DataFrame(bento_picks)
    
    return portfolios

def calculate_simulated_return(portfolio_df, weight_pct=1.0):
    # Virtual Return: Sum of (1mo return * weight)
    # Simple equal weight
    if portfolio_df.empty: return 0.0
    avg_ret = portfolio_df['1mo'].mean()
    return avg_ret # This is portfolio return over last month

# --- Logic Functions: Momentum Master (New) ---

# --- Logic Functions: Momentum Master (Offline Logic Integration) ---
# Constants are imported from market_logic.


@st.cache_data(ttl=86400)
def translate_to_japanese(text):
    """
    Translates text to Japanese using deep_translator.
    """
    if not text:
        return ""
    try:
        # Simple truncation to avoid limits (Google Translate max 5000 chars, usually fine)
        translator = GoogleTranslator(source='auto', target='ja')
        return translator.translate(text)
    except Exception as e:
        return text

@st.cache_data(ttl=None)
def load_metadata_cache(mtime):
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
    mtime: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã®ãŸã‚ã®æ›´æ–°æ™‚åˆ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    Returns: dict {ticker: {'name': str, 'industry': str, 'summary': str}}
    """
    cache_path = "data/metadata_cache.json"
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

@st.cache_data(ttl=3600)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ1æ™‚é–“ï¼‰
def get_ticker_metadata(ticker):
    """
    Fetches info (Short Name, Sector/Industry, Summary) for a single ticker.
    Returns: (name, category_label, summary_text)
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆã€ãªã‘ã‚Œã°APIå‘¼ã³å‡ºã—
    """
    # 1. Try Cache First (Fast Path)
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«ã™ã‚‹
    cache_path = "data/metadata_cache.json"
    mtime = 0
    if os.path.exists(cache_path):
        mtime = os.path.getmtime(cache_path)
    
    metadata_cache = load_metadata_cache(mtime)
    
    if ticker in metadata_cache:
        data = metadata_cache[ticker]
        name = data.get('name', ticker)
        industry = data.get('industry', '')
        summary = data.get('summary', '')
        
        # categoryå„ªå…ˆé †ä½: industry > 'Unknown'
        category = industry if industry else 'ğŸŒŠ Market Mover'
        
        return name, category, summary
    
    # 2. Fallback to API (Slow Path - for new tickers not in cache)
    try:
        t = yf.Ticker(ticker)
        info = t.info
        name = info.get('shortName', info.get('longName', ticker))
        
        # Priority: Industry > Sector > 'Unknown'
        industry = info.get('industry')
        sector = info.get('sector')
        category = industry if industry else (sector if sector else 'ğŸŒŠ Market Mover')
        
        # Summary (First 160 chars, no translation for performance)
        summary_en = info.get('longBusinessSummary', '')
        summary = ""
        if summary_en:
            summary_en = summary_en.replace('\n', ' ').strip()
            if len(summary_en) > 160:
                summary_en = summary_en[:160]
            # ç¿»è¨³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼šé€šå¸¸ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ—¥æœ¬èªãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ï¼‰
            try:
                summary = translate_to_japanese(summary_en)
            except:
                summary = summary_en  # ç¿»è¨³å¤±æ•—æ™‚ã¯è‹±èªã®ã¾ã¾
        
        return name, category, summary
    except:
        # 3. Last Resort Fallback
        if 'dynamic_names' in st.session_state:
            if ticker in st.session_state['dynamic_names']:
                return st.session_state['dynamic_names'][ticker], 'ğŸŒŠ Market Mover', ''
        
        return ticker, 'ğŸŒŠ Market Mover', ''

@st.cache_data(ttl=None) # TTLãªã—ã€‚å¼•æ•°ã®mtimeãŒå¤‰ã‚ã‚‹ã¾ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¶­æŒ
def load_cached_data(mtime_param):
    """
    ä¿å­˜ã•ã‚ŒãŸCSVã¨Pickleã‚’èª­ã¿è¾¼ã‚€ã€‚
    mtime_param: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åŠ¹åŒ–ï¼ˆæ›´æ–°æ¤œçŸ¥ï¼‰ã«ä½¿ã‚ã‚Œã‚‹æ“¬ä¼¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """
    if os.path.exists("data/momentum_cache.csv") and os.path.exists("data/history_cache.pkl"):
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
            df = pd.read_csv("data/momentum_cache.csv")
            with open("data/history_cache.pkl", "rb") as f:
                history = pickle.load(f)
            
            # æ›´æ–°æ™‚åˆ»ã®ç¢ºèª
            last_update = "Unknown"
            if os.path.exists("data/last_updated.txt"):
                with open("data/last_updated.txt", "r") as f:
                    last_update = f.read().strip()
                    
            return df, history, last_update
        except Exception as e:
            st.warning(f"Cache load failed: {e}. Falling back to live fetch.")
    
    # åˆå›èµ·å‹•æ™‚ãªã©ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã€market_logicã‚’ä½¿ã£ã¦ç›´æ¥å–å¾—
    candidates = market_logic.get_momentum_candidates()
    df, hist = market_logic.calculate_momentum_metrics(candidates)
    if df is not None:
        return df, hist, "Live Fetch (No Cache Found)"
    return None, None, "Failed"

# ... (Previous code) ...
# Note: I am not including the entire file content here, just the function replacement. 
# But wait, I need to replace the call site too which is far away.
# I will do this in two steps to be safe.
# First Tool Call: Update load_cached_data definition (Lines 695-723)
# Second Tool Call: Update call site (Lines 1101-1107)

# THIS IS THE FIRST TOOL CALL CONTENT FOR load_cached_data


# Page Config (Must be first Streamlit command)
st.set_page_config(
    page_title="Momentum Master",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "# Momentum Master\nPowered by AI Analyst"
    }
)

# --- Main App ---
def main():
    # st.set_page_config is now called globally at line 15 (actually 20 in original, but we replaced it)
    
# --- Hide Streamlit Style (Force Z-Index Method) ---
    hide_st_style = """
        <style>
        /* 1. ãƒ˜ãƒƒãƒ€ãƒ¼ã®èƒŒæ™¯ã¯é€æ˜ã«ã™ã‚‹ */
        header[data-testid="stHeader"] {
            background: transparent !important;
            border-bottom: none !important;
            pointer-events: none !important; /* ãƒ˜ãƒƒãƒ€ãƒ¼è‡ªä½“ã®ã‚¯ãƒªãƒƒã‚¯åˆ¤å®šã‚’æ¶ˆã™ */
        }

        /* 2. å³ä¸Šã®ä¸è¦ãªè¦ç´ ã‚’æ¶ˆã™ */
        [data-testid="stHeaderActionElements"] { display: none !important; }
        [data-testid="stToolbar"] { display: none !important; }
        [data-testid="stDecoration"] { display: none !important; }
        [data-testid="stStatusWidget"] { display: none !important; }

        /* 3. ãƒ•ãƒƒã‚¿ãƒ¼å®Œå…¨æ¶ˆå» */
        footer { visibility: hidden !important; height: 0px !important; }
        [data-testid="stFooter"] { display: none !important; }
        div[class^='viewerBadge'] { display: none !important; }

        /* 4. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ */
        .block-container {
            padding-top: 3rem !important;
        }
        </style>
    """
    st.markdown(hide_st_style, unsafe_allow_html=True)

    # --- Sidebar: Global Navigation REMOVED ---
    
    # Run Momentum Master
    render_momentum_master()



# --- View: Correlation Radar ---
def render_correlation_radar():
    st.title("ğŸ“Š Market Correlation Radar")
    st.markdown("""
    **ç›®çš„**: ç‚ºæ›¿ã€æ ªå¼ã€å‚µåˆ¸ã€æš—å·è³‡ç”£ãªã©ã€ç•°ãªã‚‹ã‚¢ã‚»ãƒƒãƒˆé–“ã®ã€Œç¾åœ¨ã®é€£å‹•æ€§ã€ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
    å˜ãªã‚‹ä¾¡æ ¼æ¯”è¼ƒã§ã¯ãªãã€**æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆå¤‰åŒ–ç‡ï¼‰** ã«åŸºã¥ãç´”ç²‹ãªç›¸é–¢ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    """)
    
    # Load Settings (Only once per session)
    if 'tickers' not in st.session_state:
        st.session_state['tickers'] = ["USDJPY=X", "^TNX", "GLD", "QQQ", "SMH", "BTC-USD", "XLP", "XLV"]
            
    if 'period' not in st.session_state:
        st.session_state['period'] = "1y"

    # --- Configuration ---
    with st.sidebar:
        st.header("âš™ï¸ Radar Settings")
        
        # 1. Fetch Trending for Radar
        trending_tickers = get_dynamic_trending_tickers()
        popular_tickers = []
        if trending_tickers:
            popular_tickers.extend(["--- ğŸ”¥ Trending (Yahoo Finance) ---"] + trending_tickers)
        popular_tickers.extend(STATIC_MENU_ITEMS)
        
        # Merge saved tickers
        current_selection = st.session_state.get('tickers', [])
        options = list(popular_tickers)
        for t in current_selection:
            if t not in options:
                options.append(t)

        tickers_input = st.multiselect(
            "å¯¾è±¡éŠ˜æŸ„ (Tickers)",
            options=options,
            key="tickers",
            default=st.session_state['tickers'],
            max_selections=10
        )
        
        st.caption("â€»ã€Œ---ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚")
        
        # Custom input
        def add_custom_ticker():
            new_ticker = st.session_state.new_ticker_input.strip().upper()
            if new_ticker:
                current = list(st.session_state['tickers'])
                if new_ticker not in current:
                    if len(current) < 10:
                        current.append(new_ticker)
                        st.session_state['tickers'] = current
        
        st.text_input(
            "â• Add Ticker",
            key="new_ticker_input",
            on_change=add_custom_ticker
        )
        
        period_options = {
            '1y': '1 Year (é•·æœŸ)', '3mo': '3 Months', '1mo': '1 Month', '5d': '5 Days'
        }
        st.selectbox(
            "Analysis Period", 
            list(period_options.keys()), 
            key="period", 
            format_func=lambda x: period_options.get(x, x)
        )

    # --- Main Content ---
    if tickers_input:
        with st.spinner('Fetching Radar data...'):
            df_prices = get_data(tickers_input, st.session_state['period'])

        if df_prices is not None and not df_prices.empty:
            if len(df_prices) < 2:
                st.warning("ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã€‚æœŸé–“ã‚’å»¶ã°ã—ã¦ãã ã•ã„ã€‚")
            else:
                returns, corr_matrix, cumulative_returns = calculate_stats(df_prices)
                
                # 1. Heatmap
                st.subheader("Correlation Matrix")
                if corr_matrix is not None:
                    fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
                    sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1, center=0, ax=ax_corr, square=True)
                    st.pyplot(fig_corr, use_container_width=False)
                
                st.markdown("---")
                
                # 2. Chart
                st.subheader("Relative Performance")
                if cumulative_returns is not None:
                    fig_perf, ax_perf = plt.subplots(figsize=(10, 5))
                    for column in cumulative_returns.columns:
                        ax_perf.plot(cumulative_returns.index, cumulative_returns[column] * 100, label=column)
                    ax_perf.set_ylabel("Return (%)")
                    ax_perf.grid(True, linestyle='--', alpha=0.6)
                    ax_perf.legend(loc='upper left', bbox_to_anchor=(1, 1))
                    plt.tight_layout()
                    st.pyplot(fig_perf, use_container_width=False)
                
                # 3. AI Insights
                st.markdown("---")
                st.subheader("ğŸ“Š AI Analyst Insights")
                insights = generate_insights(corr_matrix)
                if insights:
                    for item in insights:
                        t = item['type']
                        msg = f"**{item['display']}**\n\n{item['message']}"
                        
                        if t == 'fake_hedge' or t == 'risk':
                            st.warning(msg, icon="âš ï¸")
                        elif t == 'hedge':
                            st.success(msg, icon="ğŸ›¡ï¸")
                        else:
                            st.info(msg, icon="â„¹ï¸")
                else:
                    st.info("ç‰¹ç­†ã™ã¹ãç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.error("No data found.")


import random # Add at top if not exists (handling in instruction context)

# --- AI Comment Logic ---
def generate_dynamic_comment(ticker, row):
    """
    è¤‡æ•°ã®ã‚·ã‚°ãƒŠãƒ«ã‚’è€ƒæ…®ã—ãŸã‚¹ãƒãƒ¼ãƒˆãªã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆé–¢æ•°
    """
    # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
    current_price = row.get('Price', row.get('Close', 0))
    rvol = row.get('RVOL', 0)
    rsi = row.get('RSI', 50)
    
    # Fundamentals
    short_ratio = row.get('ShortRatio', 0)

    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    sma50 = row.get('SMA50', 0)
    sma200 = row.get('SMA200', 0)
    
    # åˆ¤å®šãƒ•ãƒ©ã‚°
    try:
        is_bull_trend = sma50 > sma200       # 50æ—¥ > 200æ—¥ (ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰)
        is_bear_trend = sma50 < sma200       # 50æ—¥ < 200æ—¥ (ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰)
    except:
        is_bull_trend = False
        is_bear_trend = False
    
    # ç‰¹æ®Šåˆ¤å®š: ä¾¡æ ¼ãŒé•·æœŸç·šã‚’ãƒ–ãƒ¬ã‚¤ã‚¯ã—ã¦ã„ã‚‹å ´åˆ (ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ä¸­ã ãŒä¾¡æ ¼ã¯ä¸Š)
    is_price_above_long_term = False
    if sma200 > 0:
        is_price_above_long_term = current_price > sma200

    is_high_vol = rvol > 2.0             # å‡ºæ¥é«˜æ€¥å¢—
    is_super_vol = rvol > 5.0            # å‡ºæ¥é«˜çˆ†å¢—
    is_overbought = rsi > 70             # è²·ã‚ã‚Œã™ã
    is_oversold = rsi < 30               # å£²ã‚‰ã‚Œã™ã
    
    # Daily Return Check
    ret_1d = row.get('1d', 0)
    is_crash = ret_1d < -5.0             # 5%ä»¥ä¸Šã®æ€¥è½
    is_rocket = ret_1d > 5.0             # 5%ä»¥ä¸Šã®æ€¥é¨°
    
    # --- å„ªå…ˆåº¦SS: çŸ›ç›¾ãƒ»ç‰¹ç•°ç‚¹ï¼ˆAI Analysisï¼‰ ---

    # 0. ã€ç·Šæ€¥ã€‘è¶³å…ƒã®æ€¥è½ (ãƒˆãƒ¬ãƒ³ãƒ‰é–¢ä¿‚ãªã—ã«æœ€å„ªå…ˆã§è­¦å‘Š)
    if is_crash:
        templates = [
            f"ğŸ˜± {ticker}ãŒæ€¥è½ä¸­({ret_1d:.1f}%)ã€‚ä»Šã¯ãƒˆãƒ¬ãƒ³ãƒ‰ã‚ˆã‚Šã‚‚ã“ã®è½ä¸‹é€Ÿåº¦ã«æ³¨æ„ã€‚",
            f"ğŸ“‰ {ticker}ã«å£²ã‚Šæ®ºåˆ°ã€‚è½ã¡ã‚‹ãƒŠã‚¤ãƒ•ã¯æ´ã‚€ãªã€åº•æ‰“ã¡ã‚’ç¢ºèªã›ã‚ˆã€‚",
            f"ğŸ›‘ {ticker}ã€å±é™ºæ°´åŸŸã€‚ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã ã‚ã†ãŒä½•ã ã‚ã†ãŒã€ä»Šã®ä¸‹ã’ã¯ç„¡è¦–ã§ããªã„ã€‚"
        ]
        return random.choice(templates)

    # 1. ã€åè»¢å…†å€™ã€‘é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã¯ä¸‹å‘ãã ãŒã€ä¾¡æ ¼ã¯é•·æœŸç·šã‚’ãƒ–ãƒ¬ã‚¤ã‚¯ã—ã¦ã„ã‚‹ (Recovery)
    # ã“ã‚Œã‚’ã€Œãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ä¸­ã€ã¨å‘¼ã¶ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿè¦šã¨ã‚ºãƒ¬ã‚‹ãŸã‚ã€Œãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã€ã¨ã™ã‚‹
    if is_bear_trend and is_price_above_long_term and is_high_vol:
        templates = [
            f"ğŸš€ {ticker}ãŒé•·æœŸç·š(SMA200)ã‚’ãƒ–ãƒ¬ã‚¤ã‚¯ï¼ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰ã®å¼·åŠ›ãªåè»¢ã‚·ã‚°ãƒŠãƒ«ã€‚",
            f"ğŸ”¥ é•·æœŸã®é‡ã—ã‚’è·³ã­ã®ã‘ãŸã€‚{ticker}ã¯ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹çŠ¶æ…‹ã‚’è§£æ¶ˆã—ã€æ–°ãŸãªä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã¸å‘ã‹ã†ã‹ã€‚",
            f"ğŸ‘€ {ticker}ã«ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã®å…†ã—ã€‚SMA200è¶…ãˆã¯æœ¬ç‰©ã®å¼·ã•ã®è¨¼ã€‚"
        ]
        return random.choice(templates)

    # 2. ã€åè»¢å…†å€™ã€‘ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ä¸­ã§ã€ã¾ã ä¾¡æ ¼ã‚‚ä¸‹ã ãŒã€ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãŒå¼·ã™ãã‚‹
    if is_bear_trend and (not is_price_above_long_term) and is_high_vol and is_overbought:
        templates = [
            f"âš¡ {ticker}ã«ç•°å¤‰ã€‚é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã¯ä¸‹å‘ãã ãŒã€ã“ã®RSIã¨å‡ºæ¥é«˜ã¯å¼·ã™ãã‚‹ã€‚ã€Œåˆå‹•ã€ã®å¯èƒ½æ€§ã‚‚ã€‚",
            f"ğŸ”¥ å£²ã‚Šæ–¹ã¯é€ƒã’ã‚ï¼{ticker}ã¯ä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åŠ›æŠ€ã§ã­ã˜ä¼ã›ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚",
            f"ğŸ¤” {ticker}ã€ãŸã ã®ãƒªãƒã‚¦ãƒ³ãƒ‰ã«ã—ã¦ã¯å¼·ã™ãã‚‹ã€‚ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒãƒ¼ï¼ˆè¸ã¿ä¸Šã’ï¼‰ç™ºç”Ÿä¸­ã‹ï¼Ÿ"
        ]
        return random.choice(templates)

    # 3. ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ã®æ€¥è½ï¼ˆæŠ¼ã—ç›®ã‹å´©å£Šã‹ï¼‰
    if is_bull_trend and is_high_vol and is_oversold:
        templates = [
            f"ğŸ”ª {ticker}ãŒä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ã«æ€¥è½ã€‚æŠ¼ã—ç›®è²·ã„ãƒãƒ£ãƒ³ã‚¹ã‹ã€ãã‚Œã¨ã‚‚ãƒŠã‚¤ãƒ•ã‹ï¼Ÿ",
            f"ğŸ“‰ ãƒ‘ãƒ‹ãƒƒã‚¯å£²ã‚Šç™ºç”Ÿä¸­ã€‚{ticker}ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãŒæœ¬ç‰©ãªã‚‰ã€ã“ã“ãŒçµ¶å¥½ã®æ‹¾ã„å ´ã ãŒ...",
            f"ğŸš‘ {ticker}ã€æ•‘æ€¥è»Šé€šéã€‚éç†±æ„Ÿã¯å†·ã‚ãŸãŒã€å†·ã‚ã™ãã‹ã‚‚ã—ã‚Œãªã„ã€‚"
        ]
        return random.choice(templates)

    # 4. é–‘æ•£ã¨ã—ãŸã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ï¼ˆé¨™ã—è­¦æˆ’ï¼‰
    if is_bull_trend and rvol < 0.8: # å‡ºæ¥é«˜ãŒæ™®æ®µã‚ˆã‚Šå°‘ãªã„
        templates = [
            f"âš ï¸ {ticker}ãŒGCã—ãŸãŒã€å‡ºæ¥é«˜ãŒã‚¹ã‚«ã‚¹ã‚«ã ã€‚èª°ã‚‚æ°—ã¥ã„ã¦ã„ãªã„ã‹ã€é¨™ã—ã‹ã€‚",
            f"ğŸƒ é¢¨ãŒå¹ã‘ã°é£›ã³ãã†ãªä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã€‚{ticker}ã«ã¯ãƒ‘ãƒ¯ãƒ¼ï¼ˆå‡ºæ¥é«˜ï¼‰ãŒå¿…è¦ã ã€‚",
        ]
        return random.choice(templates)
        
    # 5. Short Squeeze Potential (High Short Ratio + Price Up + Vol Up)
    ret_1d = row.get('1d', 0)
    if ret_1d > 3.0 and is_high_vol and short_ratio > 5:
        templates = [
            f"ğŸ”¥ è¸ã¿ä¸Šã’ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆã‚¹ã‚¯ã‚¤ã‚ºï¼‰è­¦å ±ï¼{ticker}ã®å£²ã‚Šè±šãŒç„¼ã‹ã‚Œã¦ã„ã‚‹ã€‚",
            f"ğŸ¥“ ç©ºå£²ã‚Šã®è²·ã„æˆ»ã—ãŒç‡ƒæ–™ã ã€‚{ticker}ã®æ€¥é¨°ã¯æ­¢ã¾ã‚‰ãªã„ã‹ã‚‚ã€‚",
            f"ğŸ¢ {ticker}ã§ãƒãƒãƒ¼ã‚²ãƒ¼ãƒ ç™ºç”Ÿä¸­ã€‚ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«æ³¨æ„ã›ã‚ˆã€‚"
        ]
        return random.choice(templates)

    # --- å„ªå…ˆåº¦S: å¼·çƒˆãªå˜ä¸€ã‚¤ãƒ™ãƒ³ãƒˆ ---

    # å‡ºæ¥é«˜çˆ†å¢—ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰é–¢ä¿‚ãªã—ã«ä½•ã‹èµ·ãã¦ã‚‹ï¼‰
    if is_super_vol:
        return f"ğŸ“¢ {ticker}ã®å‡ºæ¥é«˜ãŒãƒã‚°ã£ã¦ã„ã‚‹(RVOL {rvol:.1f})ã€‚ææ–™ãŒå‡ºãŸã‹ï¼Ÿã‚¤ãƒŠã‚´ã‚¿ãƒ¯ãƒ¼å»ºè¨­é–‹å§‹ã€‚"
        
    # Blue Sky
    high_52 = row.get('High52', 999999)
    if current_price >= high_52 * 0.98:
         return f"ğŸš€ {ticker}ã¯é’å¤©äº•ãƒ¢ãƒ¼ãƒ‰çªå…¥ï¼ä¸Šã«ã¯å®‡å®™ã—ã‹ãªã„ã€‚"

    # --- å„ªå…ˆåº¦A: é€šå¸¸ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ¤å®š ---
    
    # Squeeze
    # Squeeze
    if row.get('Is_Squeeze', False):
         if is_high_vol:
             return f"ğŸ’¥ {ticker}ãŒã‚¹ã‚¯ã‚¤ã‚ºã‹ã‚‰æ”¾ãŸã‚ŒãŸï¼ã‚¨ãƒãƒ«ã‚®ãƒ¼å……å¡«å®Œäº†ã€ãƒ“ãƒƒã‚°ãƒãƒ³ã®å§‹ã¾ã‚Šã‹ã€‚"
         else:
             return f"ğŸ¤ {ticker}ã¯åµã®å‰ã®é™ã‘ã•(Squeeze)ã€‚æ¬¡ã®ãƒ“ãƒƒã‚°ãƒ ãƒ¼ãƒ–ã«å‚™ãˆã‚ˆã€‚"

    # ç›´è¿‘ã§ã‚¯ãƒ­ã‚¹ã—ãŸã‹ï¼Ÿ
    if row.get('DC_Just_Now', False):
         return f"ğŸ’€ {ticker}ãŒãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹...é•·æœŸçš„ãªå†¬ã®æ™‚ä»£åˆ°æ¥ã‹ã€‚"
         
    if is_bear_trend and not is_high_vol and not is_price_above_long_term:
        return f"ğŸ’€ {ticker}ã¯é•·æœŸä¸‹è½ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šä¸­ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰ã«é€†ã‚‰ã‚ãšã€å†¬ã®æ™‚ä»£ã‚’è€ãˆå¿ã¶æ™‚ã€‚"
    
    # æ™®é€šã®ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ï¼ˆé †å½“ãªä¸Šã’ï¼‰
    if row.get('GC_Just_Now', False):
         return f"ğŸŒŸ {ticker}ãŒã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹é”æˆï¼é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã®ãƒ•ã‚¡ãƒ³ãƒ•ã‚¡ãƒ¼ãƒ¬ã€‚"

    if is_bull_trend and rsi > 50:
        return f"ğŸ‚ {ticker}ã¯é †èª¿ãªä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã€‚ç´ ç›´ã«ä¹—ã‚‹ã®ãŒå‰ã€‚"

    # å˜ãªã‚‹è²·ã‚ã‚Œã™ã
    if is_overbought:
        return f"ğŸ”¥ {ticker}ã¯ã‚¢ãƒã‚¢ãƒ(RSI {rsi:.0f})ã€‚ç«å‚·ã™ã‚‹å‰ã«åˆ©ç¢ºã‚‚æ¤œè¨ã‚’ã€‚"

    # å˜ãªã‚‹å£²ã‚‰ã‚Œã™ã
    if is_oversold:
        return f"ğŸ§Š {ticker}ã¯å£²ã‚‰ã‚Œã™ã(RSI {rsi:.0f})ã€‚è‡ªå¾‹åç™ºç‹™ã„ã®ã‚¹ã‚±ãƒ™è²·ã„ãƒãƒ£ãƒ³ã‚¹ï¼Ÿ"

    # --- ãã®ä»– ---
    templates = [
        f"ğŸ‘€ {ticker}ã¯æ§˜å­è¦‹ã€‚æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¾…ã¦ã€‚",
        f"ğŸ˜´ å‡ºæ¥é«˜ãŒè¶³ã‚Šãªã„ã€‚{ticker}ã¯å¯ã‹ã›ã¦ãŠã“ã†ã€‚",
        f"ğŸ¤” {ticker}ã®æ–¹å‘æ€§ãŒå®šã¾ã‚‰ãªã„ã€‚"
    ]
    return random.choice(templates)

# --- View: Momentum Master ---
def render_momentum_master():
    # Check File Modification Time (Trigger Cache Invalidation)
    cache_path = "data/momentum_cache.csv"
    mtime = os.path.getmtime(cache_path) if os.path.exists(cache_path) else 0

    # Load Data First
    with st.spinner('Loading data...'):
        df_metrics, history_dict, last_updated = load_cached_data(mtime)

    # Display Title & Update Time
    col_title, col_time = st.columns([0.7, 0.3])
    with col_title:
        # Styled Title: Gradient, Single Line, No Japanese
        st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@800&display=swap');
        .main-title {
            font-family: 'Inter', sans-serif;
            font-size: 2.2rem;
            font-weight: 800;
            margin: 0;
            padding: 0;
            background: -webkit-linear-gradient(45deg, #FF4B2B, #FF416C);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            line-height: 1.2;
        }
        /* Mobile Adjustment: Pixel 8a width approx 412px. Column is 70% (~290px). 
           Text needs to scale down to fit one line. */
        @media (max-width: 640px) {
            .main-title {
                font-size: 1.5rem !important;
            }
        }
        </style>
        <div style="display: flex; align-items: center; gap: 8px;">
            <span style="font-size: 2.0rem;">ğŸš€</span>
            <span class="main-title">Momentum Master</span>
        </div>
        """, unsafe_allow_html=True)
    with col_time:
        st.caption(f"ğŸ“… Last Update")
        st.success(f"**{last_updated}**", icon="â±ï¸")

    st.markdown("""
    **ç›®çš„**: ç±³å›½æ ªã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆå‹¢ã„ï¼‰ã‚’å¯è¦–åŒ–ã—ã€ä»Šæ³¨ç›®ã™ã¹ãéŠ˜æŸ„ã‚’ç´ æ—©ãç™ºè¦‹ã€‚
    """)

    if df_metrics is None or df_metrics.empty:
        st.error("Data cache is empty and live fetch failed.")
        return

    # --- UI: Control Panel ---
    st.markdown("### ğŸ¯ Focus Period Selector")
    
    period_map = {
        '1d': '1 Day (æœ¬æ—¥)',
        '5d': '5 Days (é€±é–“)',
        '1mo': '1 Month (æœˆé–“)',
        '3mo': '3 Months (å››åŠæœŸ)',
        '6mo': '6 Months (åŠå¹´)',
        'YTD': 'YTD (å¹´åˆæ¥)',
        '1y': '1 Year (å¹´é–“)'
    }
    
    # Default to 1d
    selected_period = st.selectbox(
        "ã©ã®æœŸé–“ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’è¦‹ã¾ã™ã‹ï¼Ÿ",
        options=list(period_map.keys()),
        index=0, 
        format_func=lambda x: period_map[x]
    )
    
    # --- Market Regime Auto-Detection (AI Attitude) ---
    # Calc Regime
    regime_key, regime_label, regime_color = market_logic.calculate_market_regime(df_metrics)
    selected_regime = regime_key
    
    # Hide the big banner (User wants it next to title)
    # st.markdown(f"""...""") 

    if df_metrics is None or df_metrics.empty:
        st.error("Data cache is empty and live fetch failed.")
        return
            
    # --- UI: Top 5 Filter ---
    
    # Ensure column exists
    if selected_period not in df_metrics.columns:
        st.error(f"Data for {selected_period} is missing.")
        return

    # Sort Descending
    df_sorted = df_metrics.sort_values(selected_period, ascending=False)

    # Filter: Market Movers (Dynamic) only for 1d?
    # NO: User requested to allow Market Movers for all periods, BUT with a "Consistency Filter".
    # Logic: If selected_period is long (e.g. 1mo), exclude stocks where shorter period return > long period return.
    # This filters out "Pump & Dump" or recent spikes that aren't consistent with the long term trend.
    
    # Hierarchy definition
    period_hierarchy = ['1d', '5d', '1mo', '3mo', '6mo', '1y']
    
    # Dynamic Filter
    if selected_period != '1d' and selected_period in period_hierarchy:
        # Get index
        target_idx = period_hierarchy.index(selected_period)
        
        # Check all shorter periods
        shorter_periods = period_hierarchy[:target_idx]
        
        # Filter Condition: Keep only if Return(Shorter) <= Return(Target)
        # We need to apply this to df_sorted.
        # Note: df_metrics contains all period columns.
        
        valid_indices = []
        for idx, row in df_sorted.iterrows():
            is_consistent = True
            target_ret = row[selected_period]
            
            # Skip if target is NaN
            if pd.isna(target_ret):
                continue
                
            for sp in shorter_periods:
                if sp in row and not pd.isna(row[sp]):
                    short_ret = row[sp]
                    # STRICT FILTER: If Short Return > Target Return, it implies momentum is fading or it was a spike.
                    # User: "1d(100%) > 1m(30%) -> OUT"
                    # User: "1d(10%) < 1m(30%) -> IN"
                     
                    # Tolerance? Let's use strict for now as requested.
                    if short_ret > target_ret:
                        is_consistent = False
                        break
            
            if is_consistent:
                valid_indices.append(idx)
                
        df_sorted = df_sorted.loc[valid_indices]
    
    # Also, we do NOT filter by STATIC_MOMENTUM_WATCHLIST anymore if it's consistent.
    # Unless... wait, if it's NOT in static list, it MUST be a market mover.
    # So we are now allowing Market Movers into the main ranking provided they are consistent.
    
    # Take Top 10
    top_10 = df_sorted.head(10).copy() # Copy to avoid SettingWithCopyWarning
    
    # Enrich with Name, Sector, AI Strategy, AND Earnings
    names = []
    sectors = []
    strategies = []
    earnings_dates = []
    
    for _, row in top_10.iterrows():
        t = row['Ticker']
        
        # 1. Metadata Fetch
        static_sec = TICKER_TO_SECTOR.get(t)
        d_name, d_cat, _ = get_ticker_metadata(t)
        
        names.append(d_name)
        
        if static_sec:
            sectors.append(static_sec)
        elif "ğŸŒŠ" in d_cat:
             # Logic fix: d_cat already has emoji if it comes from get_ticker_metadata default
            sectors.append(d_cat)
        else:
            sectors.append(f"ğŸŒŠ {d_cat}")
            
        # 2. AI Strategy
        strategies.append(generate_dynamic_comment(t, row))
        
        # 3. Earnings Date (Lazy fetch for Top 10 only)
        earnings_dates.append(get_earnings_next(t))
        
    top_10['Name'] = names
    top_10['Sector'] = sectors
    top_10['AI Strategy'] = strategies
    top_10['Earnings'] = earnings_dates
    
    # --- Mobile View Toggle ---
    use_mobile_view = st.toggle("ğŸ“± Card View Mode", value=True)
    
    # Define Column Config (Reusable)
    column_config = {
        "Ticker": st.column_config.TextColumn("Ticker", width="small", pinned=True),
        "Name": st.column_config.TextColumn("Company", width="medium"),
        "Sector": st.column_config.TextColumn("Sector", width="medium"),
        "Price": st.column_config.NumberColumn("Price", format="$%.2f"),
        "Signal": st.column_config.TextColumn(
            "Signal", 
            width="medium",
            help="ğŸš€:é’å¤©äº• | âœ¨:GC | ğŸ’€:DC | ğŸ¤:Squeeze | âš¡:å‡ºæ¥é«˜ | ğŸ‚:ä¸Šæ˜‡ | ğŸ›’:æŠ¼ã—ç›® | ğŸ”¥:åŠ ç†± | ğŸ»:ä¸‹é™ | ğŸ§Š:åº•å€¤"
        ),
        "AI Strategy": st.column_config.TextColumn("ğŸ¤– AI Analysis", width="large"),
        "Earnings": st.column_config.TextColumn("Earnings (Next)", width="medium"),
        selected_period: st.column_config.NumberColumn(
            f"{selected_period.upper()} Return", 
            format="%.2f%%",
        )
    }
    
    context_cols = ['Ticker', 'Name', 'Sector', selected_period, 'Price', 'Signal', 'AI Strategy', 'Earnings']

    # Signal Legend
    with st.expander("â„¹ï¸ Signal Legend (ã‚·ã‚°ãƒŠãƒ«ã®æ„å‘³)", expanded=False):
        st.markdown("""
        - ğŸš€ **é’å¤©äº• (Blue Sky)**: ç¾åœ¨ä¾¡æ ¼ãŒ52é€±é«˜å€¤ä»˜è¿‘ (High52 * 0.98ä»¥ä¸Š)ã€‚æ–°é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯ã®å¯èƒ½æ€§ã€‚
        - âœ¨ **ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ (GC)**: éå»æ•°æ—¥ä»¥å†…ã«SMA50ãŒSMA200ã‚’ä¸ŠæŠœã‘ã€‚é•·æœŸä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ã®ç¤ºå”†ã€‚
        - ğŸ’€ **ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ (DC)**: éå»æ•°æ—¥ä»¥å†…ã«SMA50ãŒSMA200ã‚’ä¸‹æŠœã‘ã€‚é•·æœŸä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ã®ç¤ºå”†ã€‚
        - ğŸ¤ **ã‚¹ã‚¯ã‚¤ãƒ¼ã‚º (Squeeze)**: ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ãŒåç¸®ä¸­ã€‚å¤§ããªä¾¡æ ¼å¤‰å‹•ã®å‰è§¦ã‚Œã€‚
        - âš¡ **é«˜å‡ºæ¥é«˜ (High Vol)**: ç›¸å¯¾å‡ºæ¥é«˜(RVOL)ãŒ2.0å€ä»¥ä¸Šã€‚å¸‚å ´ã®æ³¨ç›®åº¦ãŒé«˜ã„ã€‚
        - ğŸ‚ **ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ (Bull)**: ä¾¡æ ¼ãŒSMA50ã‚ˆã‚Šä¸Š & 3ãƒ¶æœˆãƒªã‚¿ãƒ¼ãƒ³ãŒãƒ—ãƒ©ã‚¹ã€‚
        - ğŸ» **ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ (Bear)**: ä¾¡æ ¼ãŒSMA50ã‚ˆã‚Šä¸‹ & 3ãƒ¶æœˆãƒªã‚¿ãƒ¼ãƒ³ãŒãƒã‚¤ãƒŠã‚¹ã€‚
        - ğŸ”¥ **åŠ ç†± (Overbought)**: RSIãŒ70ä»¥ä¸Šã€‚è²·ã‚ã‚Œã™ãè­¦å‘Šã€‚
        - ğŸ§Š **åº•å€¤ (Oversold)**: RSIãŒ30ä»¥ä¸‹ã€‚å£²ã‚‰ã‚Œã™ãï¼ˆåç™ºã®å¯èƒ½æ€§ï¼‰ã€‚
        - ğŸ›’ **æŠ¼ã—ç›® (Dip Buy)**: ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ä¸­ã ãŒã€çŸ­æœŸçš„ã«ã¯RSI < 45ã§èª¿æ•´ä¸­ã€‚æŠ¼ã—ç›®è²·ã„ã®å¥½æ©Ÿã‹ã€‚
        """)

    # Style Helpers (Global in this function)
    def highlight_focus(val):
        return 'background-color: #ffeb3b; color: black; font-weight: bold;' 
    
    # --- Mobile Card Helper ---
    def render_mobile_card_view(df, period, title_col='Name', subtitle_col='Sector', limit=5):
        # st.caption("ğŸ’¡ Card View") 

        # Split Data
        visible_df = df.head(limit)
        hidden_df = df.iloc[limit:]
        
        def render_rows(target_df):
            for idx, row in target_df.iterrows():
                ticker = row['Ticker']
                ret_val = row.get(period, 0)
                price = row.get('Price', 0)
                signal = row.get('Signal', '')
                comment = row.get('AI Strategy')
                if not comment:
                    comment = generate_dynamic_comment(ticker, row)
                    
                name = row.get(title_col, '')
                sub = row.get(subtitle_col, '')
                
                color = "#00FF00" if ret_val > 0 else "#FF4444"
                bg_color = "rgba(0, 255, 0, 0.1)" if ret_val > 0 else "rgba(255, 0, 0, 0.1)"
                
                # Compact CSS (Ultra Density for Small Screens)
                card_html = f"""
                <div style="
                    border: 1px solid #444; 
                    border-radius: 8px; 
                    padding: 8px 10px; 
                    margin-bottom: 4px; 
                    background-color: #0e1117; 
                    box-shadow: 0 1px 2px rgba(0,0,0,0.3);
                ">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 4px;">
                        <div>
                            <div style="display: flex; align-items: baseline; gap: 6px;">
                                <span style="font-size: 1.3em; font-weight: 900; color: #ffffff; letter-spacing: 0.5px;">{ticker}</span>
                                <span style="
                                    font-size: 1.0em; 
                                    font-weight: bold; 
                                    color: {color}; 
                                    background-color: {bg_color}; 
                                    padding: 0px 4px; 
                                    border-radius: 4px;
                                ">
                                    {ret_val:+.2f}%
                                </span>
                            </div>
                            <div style="font-size: 0.75em; color: #aaaaaa; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 200px;">{name}</div>
                        </div>
                        <div style="text-align: right;">
                            <div style="font-size: 0.9em; color: #eeeeee; font-weight: 600;">${price:.2f}</div>
                            <div style="font-size: 1.0em; margin-top: 0px;">{signal}</div>
                        </div>
                    </div>
                    <div style="
                        font-size: 0.75em; 
                        color: #cccccc; 
                        border-top: 1px solid #333; 
                        padding-top: 4px; 
                        margin-top: 4px; 
                        line-height: 1.25;
                    ">
                        ğŸ¤– {comment}
                    </div>
                </div>
                """
                st.markdown(card_html, unsafe_allow_html=True)

        # Render Top N
        render_rows(visible_df)
        
        # Render Remaining in Expander
        if not hidden_df.empty:
            remaining_count = len(hidden_df)
            with st.expander(f"ğŸ‘‡ View Remaining {remaining_count} (6-{len(df)})", expanded=False):
                render_rows(hidden_df)

    # --- ğŸš¨ Pre-Calculate Daily Signals (Inserted for Tabs Access) ---
    buy_breakout = []
    buy_reversal = []
    sells = []
    
    if history_dict:
        try:
             daily_signals = market_logic.get_todays_signals(history_dict)
             
             # Extract Lists
             buy_breakout = daily_signals.get('Buy_Breakout', [])
             buy_reversal = daily_signals.get('Buy_Reversal', [])
             sells = daily_signals.get('Sell', [])
             
             total_scanned = len(history_dict)
             
             # ALWAYS show section (User can verify scanning works)
             st.markdown(f"### ğŸ”” æœ¬æ—¥ã®å£²è²·ã‚·ã‚°ãƒŠãƒ«é€Ÿå ± <span style='font-size:0.6em; color:gray;'>(Scanned {total_scanned} stocks)</span>", unsafe_allow_html=True)
             
             cols_sig = st.columns(3)
             
             # 1. Breakout
             with cols_sig[0]:
                 if buy_breakout:
                     st.success(f"**ğŸš€ Breakout ({len(buy_breakout)})**")
                     st.caption("é«˜å€¤æ›´æ–° & ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶š")
                     df_b = pd.DataFrame(buy_breakout)
                     st.dataframe(df_b[['Ticker', 'Price', 'Reason']].style.format({'Price': '{:.2f}'}), hide_index=True)
                 else:
                     st.info("ğŸš€ Breakout: None")

             # 2. Reversal
             with cols_sig[1]:
                 if buy_reversal:
                     st.success(f"**ğŸ£ Reversal ({len(buy_reversal)})**")
                     st.caption("MACDæ°´é¢ä¸‹ã‹ã‚‰ã®åè»¢")
                     df_r = pd.DataFrame(buy_reversal)
                     st.dataframe(df_r[['Ticker', 'Reason', 'Price']].style.format({'Price': '{:.2f}'}), hide_index=True)
                 else:
                     st.info("ğŸ£ Reversal: None")

             # 3. Sells
             with cols_sig[2]:
                 if sells:
                     st.error(f"**ğŸ‘‹ Sell Signals ({len(sells)})**")
                     st.caption("Stop Loss Triggered")
                     df_s = pd.DataFrame(sells)
                     st.dataframe(df_s[['Ticker', 'Price', 'Reason']].style.format({'Price': '{:.2f}'}), hide_index=True)
                 else:
                     st.markdown("ğŸ‘‹ Sell: None")
             
             st.markdown("---")
             
        except Exception as e:
            st.error(f"Signal scan error: {e}")


    
    # --- Part 1.5: Worst 10 Stocks Calculation ---
    # Take Bottom 10 (Worst Performers) from the ORIGINAL df_metrics (unfiltered)
    # We do NOT apply the "Consistency Filter" to losers, as we want to see the absolute worst drops.
    bottom_10 = df_metrics.sort_values(selected_period, ascending=True).head(10).copy()
    
    # Enrichment for Bottom 10
    b_names = []
    b_sectors = []
    b_strategies = []
    b_earnings = []
    
    for _, row in bottom_10.iterrows():
        t = row['Ticker']
        static_sec = TICKER_TO_SECTOR.get(t)
        d_name, d_cat, _ = get_ticker_metadata(t)
        
        b_names.append(d_name)
        if static_sec:
            b_sectors.append(static_sec)
        elif "ğŸŒŠ" in d_cat:
            b_sectors.append(d_cat)
        else:
            b_sectors.append(f"ğŸŒŠ {d_cat}")
        
        b_strategies.append(generate_dynamic_comment(t, row))
        b_earnings.append(get_earnings_next(t))
        
    bottom_10['Name'] = b_names
    bottom_10['Sector'] = b_sectors
    bottom_10['AI Strategy'] = b_strategies
    bottom_10['Earnings'] = b_earnings

    bottom_10['Earnings'] = b_earnings





    # --- ğŸš¨ Opportunity Alert (Short-Term Focus) ---
    # Reconstruct raw DF from history_dict for retroactive calculation
    # Only run if we have history
    if history_dict:
        try:
             # Reconstruct MultiIndex DF: columns=(Ticker, Attributes)
             # This allows check_opportunity_alerts to slice by date easily.
             raw_history_df = pd.concat(history_dict.values(), axis=1, keys=history_dict.keys())
             
             # Calculate Alerts (Using selected period for ranking)
             # Note: This might take a second, so ideally we catch it.
             alerts = market_logic.check_opportunity_alerts(raw_history_df, period=selected_period)
             
             if alerts:
                 for a in alerts:
                     t = a['Ticker']
                     # Create a flashy alert box
                     st.success(
                         f"ğŸš¨ **Opportunity Alert: {t}**\n\n"
                         f"âœ… **3 Days Persistence**: {t} has been in the Top 10 ({selected_period}) for 3 consecutive days!\n"
                         f"âœ… **Volume Spike**: RVOL {a['RVOL']:.1f}x (Avg Vol exceeded by {(a['RVOL']-1)*100:.0f}%)"
                     )
        except Exception as e:
            # st.warning(f"Alert check skipped: {e}")
            pass

    # --- TABS Layout for Clean Screenshots ---
    tab1, tab_rev, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ† Top 10 Stocks", "ğŸ£ Reversal Hunters", "ğŸ“‰ Worst 10 Stocks", "ğŸ”¥ Hottest Themes", "ğŸ¥¶ Coldest Themes", "ğŸŒ¡ï¸ Sector Heatmap"])
    
    # 1. Top 10
    with tab1:
        st.markdown(f"### ğŸ† Top 10 Strongest Stocks<br><span style='font-size: 0.8em; color: gray;'>{period_map[selected_period]}</span>", unsafe_allow_html=True)
        if use_mobile_view:
            render_mobile_card_view(top_10, selected_period)
        else:
             st.dataframe(
                top_10[context_cols].style.applymap(
                    highlight_focus, subset=[selected_period]
                ).format({
                    selected_period: "{:+.2f}%",
                    'Price': "${:.2f}"
                }),
                column_config=column_config,
                use_container_width=True,
                hide_index=True
            )
            
    # 2. Reversal Hunters (New)
    with tab_rev:
        st.markdown(f"### ğŸ£ Reversal Candidates (MACD Golden Cross from Lows)")
        if buy_reversal:
            # Convert to DF for display
            # We need to enrich it slightly to match the card view structure if possible, 
            # or just use a simple DF for now.
            # Let's try to reuse render_mobile_card_view by creating a mock DF with necessary columns.
            rev_tickers = [item['Ticker'] for item in buy_reversal]
            
            # Filter original df_metrics to get full data for these tickers
            if df_metrics is not None:
                df_rev_full = df_metrics[df_metrics['Ticker'].isin(rev_tickers)].copy()
                
                # Add "Reason" from buy_reversal to the DF
                ticker_to_reason = {item['Ticker']: item['Reason'] for item in buy_reversal}
                df_rev_full['Signal_Reason'] = df_rev_full['Ticker'].map(ticker_to_reason)
                
                # Override AI Strategy with Reason for clarity
                df_rev_full['AI Strategy'] = df_rev_full['Signal_Reason']
                
                if use_mobile_view:
                     render_mobile_card_view(df_rev_full, selected_period)
                else:
                    # Desktop
                    st.dataframe(
                        df_rev_full[['Ticker', 'Name', 'Sector', 'Price', 'Signal_Reason', selected_period]].style.format({
                            'Price': '{:.2f}', 
                            selected_period: '{:+.2f}%'
                        }),
                        use_container_width=True,
                        hide_index=True
                    )
            else:
                st.warning("Metrics data missing.")
        else:
            st.info("No Reversal Candidates found currently.")

    # 3. Worst 10
    with tab2:
        st.markdown(f"### ğŸ“‰ Worst 10 Performers<br><span style='font-size: 0.8em; color: gray;'>{period_map[selected_period]}</span>", unsafe_allow_html=True)
        if use_mobile_view:
             render_mobile_card_view(bottom_10, selected_period)
        else:
            st.dataframe(
                bottom_10[context_cols].style.applymap(
                    lambda x: 'background-color: #ffebee; color: black;', subset=[selected_period]
                ).format({
                    selected_period: "{:+.2f}%",
                    'Price': "${:.2f}"
                }),
                column_config=column_config,
                use_container_width=True,
                hide_index=True
            )

    # --- ETF Preparation ---
    # st.header("ğŸŒ Global Theme & Sector Analysis") # In Tabs now
    
    etf_ready = False
    top_etf = pd.DataFrame()
    bottom_etf = pd.DataFrame()
    
    # 1. Prepare ETF list
    etf_tickers = list(THEMATIC_ETFS.values())
    if df_metrics is not None and not df_metrics.empty:
        df_etf = df_metrics[df_metrics['Ticker'].isin(etf_tickers)].copy()
        if not df_etf.empty and selected_period in df_etf.columns:
            ticker_to_theme = {v: k for k, v in THEMATIC_ETFS.items()}
            df_etf['Theme'] = df_etf['Ticker'].map(ticker_to_theme)
            df_etf_sorted = df_etf.sort_values(selected_period, ascending=False)
            top_etf = df_etf_sorted.head(10).copy()
            bottom_etf = df_etf_sorted.tail(10).sort_values(selected_period, ascending=True).copy()
            etf_ready = True

    # 3. Hottest Themes
    with tab3:
        st.subheader(f"ğŸ”¥ Hottest Themes ({period_map[selected_period]})")
        if etf_ready:
            if use_mobile_view:
                render_mobile_card_view(top_etf, selected_period, title_col='Theme', subtitle_col='Ticker')
            else:
                 etf_cols = {
                    "Theme": st.column_config.TextColumn("Theme (Sector)", width="medium"),
                    "Ticker": st.column_config.TextColumn("ETF", width="small"),
                    "Price": st.column_config.NumberColumn("Price", format="$%.2f"),
                    "Signal": st.column_config.TextColumn("Signal", width="small"),
                    selected_period: st.column_config.NumberColumn(f"{selected_period.upper()} Return", format="%.2f%%")
                }
                 etf_display_cols = ['Theme', 'Ticker', 'Price', 'Signal', selected_period]
                 st.dataframe(
                    top_etf[etf_display_cols].style.applymap(
                        highlight_focus, subset=[selected_period]
                    ).format({selected_period: "{:+.2f}%", 'Price': "${:.2f}"}),
                    column_config=etf_cols, use_container_width=True, hide_index=True
                )
        else:
            st.info("No ETF Data")

    # 4. Coldest Themes
    with tab4:
        st.subheader(f"ğŸ¥¶ Coldest Themes ({period_map[selected_period]})")
        if etf_ready:
            if use_mobile_view:
                render_mobile_card_view(bottom_etf, selected_period, title_col='Theme', subtitle_col='Ticker')
            else:
                 # Reuse etf_cols
                 etf_display_cols = ['Theme', 'Ticker', 'Price', 'Signal', selected_period]
                 st.dataframe(
                    bottom_etf[etf_display_cols].style.applymap(
                         lambda x: 'background-color: #ffebee; color: black;', subset=[selected_period]
                    ).format({selected_period: "{:+.2f}%", 'Price': "${:.2f}"}),
                    # Re-define config here or assume avail
                    column_config={
                        "Theme": st.column_config.TextColumn("Theme (Sector)", width="medium"),
                        "Ticker": st.column_config.TextColumn("ETF", width="small"),
                        selected_period: st.column_config.NumberColumn(format="%.2f%%")
                    }, 
                    use_container_width=True, hide_index=True
                )
        else:
            st.info("No ETF Data")
    
    st.markdown("---")
    
    # --- UI: Chart ---
    # --- UI: Chart ---
    # Collapsible Chart
    with st.expander(f"ğŸ“ˆ Performance Comparison (Top 10: {selected_period})", expanded=False):
        top_tickers = top_10['Ticker'].tolist()
        
        if top_tickers:
            fig, ax = plt.subplots(figsize=(10, 5))
            
            # Decide chart window based on period (approx trading days)
            window_map = {
                '1d': 2, '5d': 5, '1mo': 22, '3mo': 65, '6mo': 130, 'YTD': 252, '1y': 252
            }
            days = window_map.get(selected_period, 65)
            
            for t in top_tickers:
                if t in history_dict:
                    s = history_dict[t]
                    
                    # Slice data to relevant period + padding
                    # If dataframe is shorter than days, take all
                    slice_data = s.tail(days)
                    if slice_data.empty: continue
                    
                    # Rebase to 0% at start of chart
                    rebased = (slice_data / slice_data.iloc[0] - 1) * 100
                    ax.plot(rebased.index, rebased, label=t)
            
            ax.set_ylabel("Return (%)")
            ax.set_title(f"Relative Performance (Last ~{days} Trading Days)")
            ax.grid(True, linestyle='--', alpha=0.5)
            ax.legend()
            st.pyplot(fig, use_container_width=True)

    # --- UI: News Section for Top Stocks ---
    # (News Section Removed for Compactness / or moved down? User didn't ask to remove, but previous context had it. Keeping it is fine.)
    # Actually, let's keep the user flow: Lists -> Chart -> News -> Heatmap -> Portfolio.
    
    st.markdown("---")
    st.subheader("ğŸ“° Latest News & Analysis")
    st.caption("ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰ ä¸Šæ˜‡ç‡Top 10 éŠ˜æŸ„ã‚’é¸ã‚“ã§ã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆAIã«ã‚ˆã‚‹ã‚¿ã‚¤ãƒˆãƒ«ç¿»è¨³ãƒ»è¦ç´„æ©Ÿèƒ½ä»˜ãï¼‰")
    
    # Select box default to top 1
    default_ix = 0 if len(top_tickers) > 0 else None
    
    if top_tickers:
        news_ticker = st.selectbox("Select Ticker to View News:", top_tickers, index=default_ix)
        
        # Clear stale session_state keys when ticker changes
        if 'last_news_ticker' not in st.session_state:
            st.session_state['last_news_ticker'] = None
        
        if news_ticker != st.session_state['last_news_ticker']:
            # Cleanup old summary keys
            keys_to_remove = [k for k in st.session_state.keys() if k.startswith('sum_') or k.startswith('btn_')]
            for k in keys_to_remove:
                del st.session_state[k]
            st.session_state['last_news_ticker'] = news_ticker
        
        if news_ticker:
            selected_row = top_10[top_10['Ticker'] == news_ticker]
            if not selected_row.empty:
                c_name = selected_row.iloc[0]['Name']
            else:
                c_name, _, _ = get_ticker_metadata(news_ticker)

            with st.spinner(f"Fetching news for {news_ticker} ({c_name})..."):
                news_items = get_ticker_news(news_ticker, company_name=c_name)
                if news_items:
                    # Initialize summary storage for this ticker if not exists
                    if 'news_summaries' not in st.session_state:
                        st.session_state['news_summaries'] = {}
                    if news_ticker not in st.session_state['news_summaries']:
                        st.session_state['news_summaries'][news_ticker] = {}
                    
                    # WORKAROUND: Dummy element to absorb Streamlit Cloud orphan widget bug
                    st.markdown("<div style='display:none;'></div>", unsafe_allow_html=True)
                    
                    for idx, item in enumerate(news_items):
                        pub_str = f" ({item['publisher']})" if item['publisher'] != 'Unknown' else ""
                        with st.expander(f"ğŸ“° {item['title']}{pub_str}", expanded=True):
                            st.write(f"**Published**: {item['time']}")
                            st.write(f"[Read Article]({item['link']})")

                            # Check if summary already exists for this article
                            summary_key = str(idx)
                            stored_summary = st.session_state['news_summaries'][news_ticker].get(summary_key)
                            
                            if stored_summary:
                                st.success("âœ… Deep Summary Generated")
                                st.info(stored_summary)
                            else:
                                btn_key = f"btn_{news_ticker}_{idx}"
                                if st.button("âœ¨ AIè©³ç´°è¦ç´„ (Read Article)", key=btn_key):
                                    with st.spinner("è¨˜äº‹ã‚’è§£æä¸­... (ã“ã‚Œã«ã¯æ•°ç§’ã‹ã‹ã‚Šã¾ã™)"):
                                        deep_val = get_article_summary(item['link'])
                                        st.session_state['news_summaries'][news_ticker][summary_key] = deep_val
                                        st.rerun()
                else:
                    st.info(f"No specific news found for {news_ticker} in the last 3 days.")
    
    # --- Part 3: Sector Heatmap (New) ---
    # --- Part 3: Sector Heatmap (New) ---
    with tab5:
        st.markdown(f"<h2>ğŸŒ¡ï¸ Sector Heatmap<br><span style='font-size: 0.6em; color: gray;'>{period_map[selected_period]}</span></h2>", unsafe_allow_html=True)
        st.caption("å„ã‚»ã‚¯ã‚¿ãƒ¼ã®ã€Œå‹ã¡çµ„ Top 3ã€ã¨ã€Œè² ã‘çµ„ Bottom 3ã€ã‚’ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤º")

    SECTOR_JP_MAP = {
        # --- 1. Semi & AI Compute ---
        "ğŸ§  Semi: AI Compute & Logic": "ğŸ§  åŠå°ä½“: AIã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆ & ãƒ­ã‚¸ãƒƒã‚¯",
        "ğŸ—ï¸ Semi: Equipment & Foundry": "ğŸ—ï¸ åŠå°ä½“: è£½é€ è£…ç½® & ãƒ•ã‚¡ã‚¦ãƒ³ãƒ‰ãƒª",
        "ğŸ–¥ï¸ AI Infra: Server & Memory": "ğŸ–¥ï¸ AIã‚¤ãƒ³ãƒ•ãƒ©: ã‚µãƒ¼ãƒãƒ¼ & ãƒ¡ãƒ¢ãƒª",
        "ğŸ”Œ Semi: Analog & Power": "ğŸ”Œ åŠå°ä½“: ã‚¢ãƒŠãƒ­ã‚° & ãƒ‘ãƒ¯ãƒ¼",
        
        # --- 2. AI Software & Security ---
        "ğŸ§  AI: Big Tech": "ğŸ§  AI: ãƒ“ãƒƒã‚°ãƒ†ãƒƒã‚¯",
        "ğŸ›¡ï¸ AI: Cybersecurity": "ğŸ›¡ï¸ AI: ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
        "â˜ï¸ AI: SaaS & Data Apps": "â˜ï¸ AI: SaaS & ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒª",
        "ğŸ¤– Robotics & Automation": "ğŸ¤– ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ & è‡ªå‹•åŒ–",
        
        # --- 3. Crypto & FinTech ---
        "ğŸª™ Crypto: Miners & Assets": "ğŸª™ ã‚¯ãƒªãƒ—ãƒˆ: ãƒã‚¤ãƒŠãƒ¼ & è³‡ç”£",
        "ğŸ’³ FinTech & Payments": "ğŸ’³ ãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯: æ±ºæ¸ˆ",
        
        # --- 4. Defense & Space ---
        "ğŸ›¡ï¸ Defense: Major Contractors": "ğŸ›¡ï¸ é˜²è¡›: å¤§æ‰‹è«‹è² ",
        "ğŸš€ Space & Future Mobility": "ğŸš€ å®‡å®™: å®‡å®™ & æ¬¡ä¸–ä»£ãƒ¢ãƒ“ãƒªãƒ†ã‚£",
        "ğŸš Defense: Drones & Tech": "ğŸš é˜²è¡›: ãƒ‰ãƒ­ãƒ¼ãƒ³ & ãƒ†ãƒƒã‚¯",
        
        # --- 5 & 6. Energy & Utilities ---
        "â˜¢ï¸ Energy: Nuclear": "â˜¢ï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼: åŸå­åŠ›",
        "ğŸ’¡ Utilities: Regulated": "ğŸ’¡ å…¬ç›Š: è¦åˆ¶é›»åŠ›",
        "â˜€ï¸ Energy: Solar & Clean Tech": "â˜€ï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼: å¤ªé™½å…‰ & ã‚¯ãƒªãƒ¼ãƒ³ãƒ†ãƒƒã‚¯",
        
        # --- 7. Oil & Gas ---
        "ğŸ›¢ï¸ Energy: Integrated Majors": "ğŸ›¢ï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼: çµ±åˆçŸ³æ²¹ãƒ¡ã‚¸ãƒ£ãƒ¼",
        "ğŸ—ï¸ Energy: E&P (Upstream)": "ğŸ—ï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼: E&P (ä¸Šæµ)",
        "ğŸ”§ Energy: Services & Equipment": "ğŸ”§ ã‚¨ãƒãƒ«ã‚®ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ & è¨­å‚™",
        "ğŸ›¤ï¸ Energy: Midstream": "ğŸ›¤ï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼: ãƒŸãƒƒãƒ‰ã‚¹ãƒˆãƒªãƒ¼ãƒ ",
        
        # --- 8-10. Bio & Health ---
        "ğŸ’Š BioPharma: Big Pharma & Obesity": "ğŸ’Š è£½è–¬: å¤§æ‰‹è£½è–¬ & è‚¥æº€è–¬",
        "ğŸ§¬ Biotech: Commercial Leaders": "ğŸ§¬ ãƒã‚¤ã‚ª: å•†ç”¨ãƒªãƒ¼ãƒ€ãƒ¼",
        "ğŸ§ª Biotech: Gene & Cell Therapy": "ğŸ§ª ãƒã‚¤ã‚ª: éºä¼å­ & ç´°èƒæ²»ç™‚",
        "ğŸ”¬ Biotech: Clinical & Growth": "ğŸ”¬ ãƒã‚¤ã‚ª: è‡¨åºŠ & ã‚°ãƒ­ãƒ¼ã‚¹",
        "ğŸ¦¾ MedTech & Devices": "ğŸ¦¾ åŒ»ç™‚: åŒ»ç™‚æ©Ÿå™¨ & ãƒ‡ãƒã‚¤ã‚¹",
        "ğŸ¥ Health Services & Insurers": "ğŸ¥ åŒ»ç™‚: ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã‚µãƒ¼ãƒ“ã‚¹ & ä¿é™º",
        "ğŸ“± MedTech: Digital Health & Services": "ğŸ“± åŒ»ç™‚: ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ & ã‚µãƒ¼ãƒ“ã‚¹",
        
        # --- 11-13. Consumer ---
        "ğŸ” Consumer: Restaurants": "ğŸ” æ¶ˆè²»è²¡: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³",
        "ğŸ¥¤ Consumer: Food & Bev Staples": "ğŸ¥¤ æ¶ˆè²»è²¡: é£Ÿå“ & é£²æ–™",
        "ğŸ›’ Consumer: Retail & E-Com": "ğŸ›’ æ¶ˆè²»è²¡: å°å£² & Eã‚³ãƒãƒ¼ã‚¹",
        "âœˆï¸ Consumer: Travel & Leisure": "âœˆï¸ æ¶ˆè²»è²¡: æ—…è¡Œ & ãƒ¬ã‚¸ãƒ£ãƒ¼",
        "ğŸ‘— Consumer: Apparel & Luxury": "ğŸ‘— æ¶ˆè²»è²¡: ã‚¢ãƒ‘ãƒ¬ãƒ« & ãƒ©ã‚°ã‚¸ãƒ¥ã‚¢ãƒªãƒ¼",
        
        # --- 14. Auto ---
        "ğŸš— Auto & EV": "ğŸš— è‡ªå‹•è»Š: è‡ªå‹•è»Š & EV",
        
        # --- 15. Real Estate ---
        "ğŸ“¡ Real Estate: Digital Infra": "ğŸ“¡ ä¸å‹•ç”£: ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¤ãƒ³ãƒ•ãƒ©",
        "ğŸ˜ï¸ Real Estate: Traditional": "ğŸ˜ï¸ ä¸å‹•ç”£: ä¼çµ±çš„REIT",
        "ğŸ  Homebuilders & Residential": "ğŸ  ä½å®…: ä½å®…å»ºè¨­ & ä¸å‹•ç”£",
        
        # --- 16. Finance ---
        "ğŸ›ï¸ Finance: Mega Banks": "ğŸ›ï¸ é‡‘è: ãƒ¡ã‚¬ãƒãƒ³ã‚¯",
        "ğŸ¦ Finance: Regional Banks": "ğŸ¦ é‡‘è: åœ°æ–¹éŠ€è¡Œ",
        "ğŸ“ˆ Finance: Capital Markets & PE": "ğŸ“ˆ é‡‘è: è³‡æœ¬å¸‚å ´ & PE",
        "ğŸ’³ Finance: Credit Cards": "ğŸ’³ é‡‘è: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰", # Old Key Cleanup might be needed if logic changed in market_logic, but I checked key is 'Credit Cards & Consumer'
        "ğŸ’³ Finance: Credit Cards & Consumer": "ğŸ’³ é‡‘è: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ & æ¶ˆè²»è€…é‡‘è",
        "â˜‚ï¸ Finance: Insurance": "â˜‚ï¸ é‡‘è: ä¿é™º",
        
        # --- 17. Industrials ---
        "ğŸ­ Industrials: Machinery": "ğŸ­ è³‡æœ¬è²¡: æ©Ÿæ¢° & è£½é€ ",
        "âœˆï¸ Transport & Logistics": "âœˆï¸ è¼¸é€: ç‰©æµ & è¼¸é€",
        "ğŸ—ï¸ Engineering & Construction": "ğŸ—ï¸ å»ºè¨­: ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° & å»ºè¨­",
        
        # --- 18. Resources ---
        "ğŸ¥‡ Resources: Gold & Silver": "ğŸ¥‡ è³‡æº: é‡‘ & éŠ€",
        "ğŸ—ï¸ Resources: Base Metals (Cu, Fe, Al)": "ğŸ—ï¸ è³‡æº: ãƒ™ãƒ¼ã‚¹ãƒ¡ã‚¿ãƒ« (éŠ…é‰„ã‚¢ãƒ«ãƒŸ)",
        "ğŸ”‹ Resources: Battery & EV Materials": "ğŸ”‹ è³‡æº: é›»æ± ææ–™ & EVç´ æ",
        "ğŸ§² Resources: Rare Earths & Specialty": "ğŸ§² è³‡æº: ãƒ¬ã‚¢ã‚¢ãƒ¼ã‚¹ & ç‰¹æ®Šé‡‘å±",
        "âš—ï¸ Resources: Chemicals & Materials": "âš—ï¸ è³‡æº: åŒ–å­¦ & ç´ æ",
        "ğŸ’ Resources: PGM & Royalty": "ğŸ’ è³‡æº: ç™½é‡‘æ— & ãƒ­ã‚¤ãƒ¤ãƒ«ãƒ†ã‚£",
        
        # --- Tech ---
        "âš›ï¸ Tech: Quantum Computing": "âš›ï¸ ãƒ†ãƒƒã‚¯: é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿"
    }
    
    def render_sector_heatmap(df, period):
        # 1. Calculate Sector Performance
        sector_stats = []
        for sector_name, tickers in SECTOR_DEFINITIONS.items():
            df_sec = df[df['Ticker'].isin(tickers)]
            if df_sec.empty: continue
            
            # Use Japanese Name for EVERYTHING now
            jp_name = SECTOR_JP_MAP.get(sector_name, sector_name)
            
            avg_ret = df_sec[period].mean()
            sector_stats.append({
                'name': jp_name, # Storing JP Name
                'avg': avg_ret,
                'tickers': tickers,
                'df': df_sec
            })
            
        # Sort by Avg Return
        sector_stats.sort(key=lambda x: x['avg'], reverse=True)
        
        if not sector_stats: return

        st.markdown(f"### ğŸ“Š Sector Momentum Ranking <span style='font-size:0.8em; color:gray;'>(Click 'Details' to expand)</span>", unsafe_allow_html=True)
        
        # Styles (flush left HTML) - Restored Style A
        styles = """
<style>
.rank-card {
    background-color: #151515;
    border-radius: 10px;
    padding: 12px 16px;
    margin-bottom: 2px; /* Close gap to expander */
    display: grid;
    grid-template-columns: 40px 1fr 100px 120px;
    align-items: center;
    gap: 10px;
    border: 1px solid #333;
    transition: transform 0.2s;
}
.rank-card:hover { border-color: #555; }

.rank-num { font-size: 1.4rem; font-weight: 900; color: #555; text-align: center; }
.rank-1 { color: #FFD700; text-shadow: 0 0 10px rgba(255, 215, 0, 0.5); }
.rank-2 { color: #C0C0C0; text-shadow: 0 0 10px rgba(192, 192, 192, 0.3); }
.rank-3 { color: #CD7F32; text-shadow: 0 0 10px rgba(205, 127, 50, 0.3); }

.sec-name { font-weight: 700; font-size: 1.0rem; color: #eee; }
.sec-meta { font-size: 0.75rem; color: #aaa; display: flex; gap: 10px; margin-top: 4px; }
.win-rate { background: #333; padding: 2px 6px; border-radius: 4px; }

.top-gainer { font-size: 0.8rem; color: #888; text-align: right; }
.gainer-tick { color: #bbb; font-weight: 600; }

.ret-box { text-align: right; }
.ret-val { font-size: 1.2rem; font-weight: 800; }
.ret-bar-bg { width: 100%; height: 4px; background: #333; border-radius: 2px; margin-top: 4px; overflow: hidden; }
.ret-bar-fill { height: 100%; border-radius: 2px; }

/* Mobile adjustment */
@media (max-width: 600px) {
    .rank-card { grid-template-columns: 30px 1fr 80px; }
    .top-gainer { display: none; }
}
</style>
"""
        st.markdown(styles, unsafe_allow_html=True)

        # Helper to render a single sector block (HYBRID: Card + Expander)
        def render_sector_block(stat, i, max_abs_ret):
            rank = i + 1
            avg = stat['avg']
            df_s = stat['df']
            
            # Rank Style
            rank_class = "rank-num"
            icon = f"{rank}"
            if rank == 1: 
                rank_class += " rank-1"
                icon = "ğŸ¥‡"
            elif rank == 2: 
                rank_class += " rank-2"
                icon = "ğŸ¥ˆ"
            elif rank == 3: 
                rank_class += " rank-3"
                icon = "ğŸ¥‰"
            
            # Color Logic
            if avg >= 0:
                val_color = "#00FF00"
                bar_color = "linear-gradient(90deg, #004400, #00FF00)"
            else:
                val_color = "#FF4444"
                bar_color = "linear-gradient(90deg, #440000, #FF4444)"
                
            # Bar Width
            bar_width = min(100, (abs(avg) / max_abs_ret) * 100)
            
            # Meta Stats
            win_count = len(df_s[df_s[period] > 0])
            total_count = len(df_s)
            win_rate_str = f"Win {win_count}/{total_count}"
            
            top_gainer = df_s.sort_values(period, ascending=False).iloc[0] if not df_s.empty else None
            gainer_html = ""
            if top_gainer is not None:
                gainer_html = f"ğŸš€ {top_gainer['Ticker']} <span class='gainer-tick'>{top_gainer[period]:+.1f}%</span>"

            # 1. Render Visual Card
            card_html = f"""
<div class="rank-card">
    <div class="{rank_class}">{icon}</div>
    <div>
        <div class="sec-name">{stat['name']}</div>
        <div class="sec-meta">
            <span class="win-rate">{win_rate_str}</span>
        </div>
    </div>
    <div class="top-gainer">{gainer_html}</div>
    <div class="ret-box">
        <div class="ret-val" style="color: {val_color};">{avg:+.2f}%</div>
        <div class="ret-bar-bg">
            <div class="ret-bar-fill" style="width: {bar_width}%; background: {bar_color};"></div>
        </div>
    </div>
</div>
"""
            st.markdown(card_html, unsafe_allow_html=True)
            
            # 2. Render Detail Expander BELOW the card
            with st.expander("ğŸ”½ å…¨éŠ˜æŸ„ã‚’è¡¨ç¤º / Show Details", expanded=False):
                # Inside: Render ALL tickers in this sector
                df_sorted = df_s.sort_values(period, ascending=False)
                cols_grid = st.columns(3) if not use_mobile_view else st.columns(1)
                for idx, row in df_sorted.iterrows():
                    ticker = row['Ticker']
                    ret_val = row.get(period, 0)
                    price = row.get('Price', 0)
                    color = "#00FF00" if ret_val > 0 else "#FF4444"
                    bg_color = "rgba(0, 255, 0, 0.1)" if ret_val > 0 else "rgba(255, 0, 0, 0.1)"
                    
                    mini_card = f"""
                    <div style="border: 1px solid #444; border-radius: 6px; padding: 8px; margin-bottom: 6px; background-color: #0e1117;">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div>
                                <span style="font-weight: bold; font-size: 1.1em; color: #eee;">{ticker}</span>
                                <span style="font-size: 0.8em; color: #aaa;">${price:.2f}</span>
                            </div>
                            <span style="font-weight: bold; color: {color}; background-color: {bg_color}; padding: 2px 6px; border-radius: 4px; font-size: 0.9em;">
                                {ret_val:+.2f}%
                            </span>
                        </div>
                    </div>
                    """
                    if use_mobile_view:
                        st.markdown(mini_card, unsafe_allow_html=True)
                    else:
                        with cols_grid[idx % 3]:
                            st.markdown(mini_card, unsafe_allow_html=True)

        # Determine Max Return for Bar scaling
        max_abs_ret = 0.1
        if sector_stats:
            max_val = max([abs(x['avg']) for x in sector_stats])
            if max_val > 0: max_abs_ret = max_val

        # Logic to Split Top/Middle/Bottom
        if len(sector_stats) > 10:
             # Top 5
             for i in range(5):
                 render_sector_block(sector_stats[i], i, max_abs_ret)
             
             # Middle
             middle_count = len(sector_stats) - 10
             mid_start = 5
             mid_end = len(sector_stats) - 5
             
             st.markdown(f"<div style='margin: 10px 0;'>", unsafe_allow_html=True)
             if st.checkbox(f"ğŸ”½ 6ä½ ã€œ {mid_end}ä½ ã‚’è¡¨ç¤º ({middle_count}ã‚»ã‚¯ã‚¿ãƒ¼)", value=False):
                 for i in range(mid_start, mid_end):
                     render_sector_block(sector_stats[i], i, max_abs_ret)
             st.markdown("</div>", unsafe_allow_html=True)
             
             # Bottom 5
             for i in range(mid_end, len(sector_stats)):
                 render_sector_block(sector_stats[i], i, max_abs_ret)
                 
        else:
             # Regular Full List
             for i, stat in enumerate(sector_stats):
                 render_sector_block(stat, i, max_abs_ret)

        st.markdown("---")


            

        
    if df_metrics is not None:
        with tab5:
            render_sector_heatmap(df_metrics, selected_period)

    
    # --- Part 4: ğŸ¤– AI Portfolio Builder ---
    
    # --- UI: ğŸ¯ AI Stock Picks (Before AI Portfolio Builder) ---
    st.markdown("---")
    
    # Custom Header with Regime Label
    st.markdown(f"""
    <div style="display: flex; align-items: center; gap: 15px; margin-bottom: 10px;">
        <h3 style="margin: 0;">ğŸ¯ AIéŠ˜æŸ„ãƒ”ãƒƒã‚¯</h3>
        <div style="
            background-color: #1E1E1E; 
            border: 1px solid {regime_color}; 
            color: {regime_color}; 
            padding: 2px 10px; 
            border-radius: 12px; 
            font-size: 0.9rem; 
            font-weight: bold;
            display: flex; align-items: center; gap: 5px;
        ">
            <span>ğŸ§  {regime_label}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

    with st.expander("æŠ•è³‡æœŸé–“åˆ¥ã‚ªã‚¹ã‚¹ãƒ¡éŠ˜æŸ„ (è©³ç´°)", expanded=True):
        st.caption("çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®å„è¦³ç‚¹ã‹ã‚‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã€ãƒˆãƒƒãƒ—3éŠ˜æŸ„ã‚’è‡ªå‹•é¸å‡ºã—ã¾ã™ã€‚")
        
        # Get ETF metrics from the same cache (they are in df_metrics)
        etf_tickers = list(THEMATIC_ETFS.values())
        etf_df = df_metrics[df_metrics['Ticker'].isin(etf_tickers)]
        
        # Get AI picks (news checker is optional, skip for performance)
        # Pass the selected regime
        ai_picks = get_ai_stock_picks(df_metrics, etf_metrics=etf_df, news_checker=None, top_n=3, regime=selected_regime)
        
        # Display in 3 columns
        col_short, col_mid, col_long = st.columns(3)
        
        timeframe_config = [
            (col_short, 'short', 'âš¡ çŸ­æœŸ (1-2é€±é–“)', '#FF6B6B'),
            (col_mid, 'mid', 'ğŸ“ˆ ä¸­æœŸ (1-3ãƒ¶æœˆ)', '#4ECDC4'),
            (col_long, 'long', 'ğŸ† é•·æœŸ (6ãƒ¶æœˆ+)', '#F4A460'),
        ]
        
        for col, tf_key, tf_label, color in timeframe_config:
            with col:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, {color}22, {color}11); 
                            border-left: 4px solid {color}; 
                            padding: 8px 12px; 
                            border-radius: 8px; 
                            margin-bottom: 10px;">
                    <span style="font-weight: 700; font-size: 0.95rem;">{tf_label}</span>
                </div>
                """, unsafe_allow_html=True)
                
                picks = ai_picks.get(tf_key, [])
                
                if not picks:
                    st.info("ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                    continue
                    
                for i, pick in enumerate(picks):
                    ticker = pick['ticker']
                    score = pick['score']
                    reason = pick['reason']
                    metrics = pick['metrics']
                    sector = metrics.get('sector', '')[:15]
                    crash_risk = pick.get('crash_risk', 0)
                    
                    # Key metric based on timeframe
                    if tf_key == 'short':
                        key_metric = f"5d: {metrics['5d']:+.1f}%"
                    elif tf_key == 'mid':
                        key_metric = f"1mo: {metrics['1mo']:+.1f}%"
                    else:
                        key_metric = f"1y: {metrics['1y']:+.1f}%"
                    
                    # Build risk factor breakdown for tooltip
                    risk_factors = []
                    rsi = metrics.get('RSI', 50)
                    if rsi > 75:
                        risk_factors.append(f"RSIéç†±({rsi:.0f})")
                    beta = metrics.get('Beta', 1.0)
                    if beta > 2:
                        risk_factors.append(f"é«˜Beta({beta:.1f})")
                    sma_dev = metrics.get('SMA50_Deviation', 0)
                    if sma_dev > 20:
                        risk_factors.append(f"SMAä¹–é›¢+{sma_dev:.0f}%")
                    inst_own = metrics.get('InstOwnership', 0)
                    if inst_own > 0.8:
                        risk_factors.append(f"æ©Ÿé–¢{inst_own*100:.0f}%")
                    
                    risk_detail = " / ".join(risk_factors) if risk_factors else ""
                    
                    # Crash risk badge with numerical display
                    if crash_risk > 50:
                        risk_badge = f'<span style="background: #FF4444; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.7rem; margin-left: 6px;" title="{risk_detail}">ğŸ”´é«˜ãƒªã‚¹ã‚¯</span>'
                        risk_bar_color = "#FF4444"
                    elif crash_risk > 30:
                        risk_badge = f'<span style="background: #FFA500; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.7rem; margin-left: 6px;" title="{risk_detail}">ğŸŸ ä¸­ãƒªã‚¹ã‚¯</span>'
                        risk_bar_color = "#FFA500"
                    elif crash_risk < 15:
                        risk_badge = f'<span style="background: #28A745; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.7rem; margin-left: 6px;">ğŸŸ¢ä½ãƒªã‚¹ã‚¯</span>'
                        risk_bar_color = "#28A745"
                    else:
                        risk_badge = ''
                        risk_bar_color = "#888"
                    
                    # Risk factor display (show below card if factors exist)
                    risk_factors_html = ""
                    if risk_factors and crash_risk > 30:
                        risk_factors_html = f'<div style="font-size: 0.65rem; color: #FF6B6B; margin-top: 4px; opacity: 0.9;">âš¡ {risk_detail}</div>'
                    
                    # Get company name and industry
                    company_name, industry, summary = get_ticker_metadata(ticker)
                    
                    # Prepare short summary
                    short_summary = summary[:80] + "..." if len(summary) > 80 else summary
                    if not short_summary:
                         short_summary = f"{company_name}ã¯{industry}ã‚»ã‚¯ã‚¿ãƒ¼ã®ä¸»è¦ä¼æ¥­ã§ã™ã€‚"
                    

                    st.markdown(f"""
                    <div style="background: rgba(255,255,255,0.05); 
                                border-radius: 8px; 
                                padding: 10px 12px; 
                                margin-bottom: 8px;
                                border: 1px solid rgba(255,255,255,0.1);">
                        <div style="display: flex; justify-content: space-between; align-items: start;">
                            <div>
                                <span style="font-weight: 700; font-size: 1.1rem; color: {color};">
                                    #{i+1} {ticker} <span style="font-size: 0.8rem; color: #aaa;">(Score: {score:.1f})</span>{risk_badge}
                                </span>
                                <div style="font-size: 0.8rem; color: #ccc; margin-top: 2px;">
                                    {company_name} | <span style="color: #4ECDC4;">{industry}</span>
                                </div>
                            </div>
                            <span style="font-size: 0.85rem; opacity: 0.8; font-weight: bold;">
                                ${metrics['price']:.2f}
                            </span>
                        </div>
                        <div style="font-size: 0.75rem; opacity: 0.7; margin: 6px 0 8px 0; font-style: italic; color: #eee; border-left: 2px solid #555; padding-left: 8px;">
                            {short_summary}
                        </div>
                        <div style="font-size: 0.9rem; font-weight: 600; color: #4CAF50; margin-bottom: 4px;">
                            {key_metric}
                        </div>
                        <div style="font-size: 0.72rem; opacity: 0.6;">
                            ğŸ’¡ {reason}
                        </div>
                        {risk_factors_html}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Score Breakdown Expander
                    with st.expander("ğŸ“Š ã‚¹ã‚³ã‚¢è©³ç´°ã‚’è¦‹ã‚‹", expanded=False):
                        details = pick.get('details', [])
                        if details:
                            # Color code details
                            for d in details:
                                if ": +" in d:
                                    color = "#4CAF50" # Green for bonus
                                    d_fmt = d.replace(":", f': <span style="color:{color}; font-weight:bold;">') + '</span>'
                                elif ": -" in d:
                                    color = "#FF4444" # Red for penalty
                                    d_fmt = d.replace(":", f': <span style="color:{color}; font-weight:bold;">') + '</span>'
                                else:
                                    d_fmt = d
                                st.markdown(f"- {d_fmt}", unsafe_allow_html=True)
                        else:
                            st.write("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        # Risk badge legend
        st.markdown("""
        <div style="margin-top: 12px; padding: 8px 12px; background: rgba(255,255,255,0.03); border-radius: 6px; font-size: 0.75rem;">
            <span style="font-weight: 600; opacity: 0.9;">ğŸ“Š ãƒªã‚¹ã‚¯ãƒãƒƒã‚¸å‡¡ä¾‹:</span>
            <span style="background: #FF4444; color: white; padding: 1px 5px; border-radius: 3px; margin-left: 8px;">ğŸ”´é«˜ãƒªã‚¹ã‚¯</span> <span style="opacity: 0.7;">(50+)</span>
            <span style="background: #FFA500; color: white; padding: 1px 5px; border-radius: 3px; margin-left: 8px;">ğŸŸ ä¸­ãƒªã‚¹ã‚¯</span> <span style="opacity: 0.7;">(30-50)</span>
            <span style="background: #28A745; color: white; padding: 1px 5px; border-radius: 3px; margin-left: 8px;">ğŸŸ¢ä½ãƒªã‚¹ã‚¯</span> <span style="opacity: 0.7;">(0-15)</span>
            <br><span style="opacity: 0.6; margin-top: 4px; display: inline-block;">â€»ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã¯RSIéç†±ãƒ»é«˜Betaãƒ»SMAä¹–é›¢ãƒ»æ©Ÿé–¢ä¿æœ‰ç‡ãƒ»ShortRatioç­‰ã‹ã‚‰ç®—å‡ºã€‚é«˜ãƒªã‚¹ã‚¯éŠ˜æŸ„ã¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚</span>
        </div>
        """, unsafe_allow_html=True)
        
        # Scoring Explanation Expander
        with st.expander("ğŸ“Š ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æŒ‡æ¨™ã®è©³ç´°èª¬æ˜", expanded=False):
            st.markdown("""
            ### ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæŠ•è³‡æœŸé–“åˆ¥ï¼‰
            
            | æŒ‡æ¨™ | çŸ­æœŸ (1-2é€±é–“) | ä¸­æœŸ (1-3ãƒ¶æœˆ) | é•·æœŸ (6ãƒ¶æœˆ+) |
            | :--- | :--- | :--- | :--- |
            | **é‡è¦–ç‚¹** | **çˆ†ç™ºåŠ›ãƒ»åˆå‹•** | **ãƒˆãƒ¬ãƒ³ãƒ‰å®‰å®šæ€§** | **æ¥­ç¸¾ãƒ»ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º** |
            | **RVOL (å‡ºæ¥é«˜)** | **æœ€é‡è¦ (30%)**<br>æ€¥å¢—ã§é«˜è©•ä¾¡ | é‡è¦ (10%)<br>ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šç¢ºèª | å‚è€ƒ (5%) |
            | **ãƒªã‚¿ãƒ¼ãƒ³** | **5æ—¥é¨°è½ (20%)**<br>åˆå‹•ã€œæ€¥ä¼¸ã‚’ç‹™ã† | **1ãƒ¶æœˆé¨°è½ (25%)**<br>å®‰å®šä¸Šæ˜‡ã‚’è©•ä¾¡ | 1å¹´/YTD (30%)<br>é•·æœŸä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ |
            | **RSI** | **90ã¾ã§è¨±å®¹ (10%)**<br>å¼·æ°—ç›¸å ´ã®éç†±ã‚’è¨±å®¹ | **éç†±è­¦æˆ’ (10%)**<br>75-85ã§æ¸›ç‚¹ã€å®‰å®šé‡è¦– | ä¸­ç«‹ (5%)<br>æ¥µç«¯ãªéç†±ãƒ»å£²ã‚‰ã‚Œã™ãå›é¿ |
            | **ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«** | **é«˜å€¤æ›´æ–° (20%)**<br>52é€±é«˜å€¤ãƒ–ãƒ¬ã‚¤ã‚¯é‡è¦– | **BBã‚¹ã‚¯ã‚¤ãƒ¼ã‚º (15%)**<br>ã‚¨ãƒãƒ«ã‚®ãƒ¼è“„ç©(æœŸé–“ãƒœãƒ¼ãƒŠã‚¹æœ‰) | ãƒˆãƒ¬ãƒ³ãƒ‰ (20%)<br>SMA200/50ä¹–é›¢ã€æŠ¼ã—ç›® |
            | **ãã®ä»–** | **ç›¸å¯¾å¼·åº¦ (RS)**<br>å¯¾ã‚»ã‚¯ã‚¿ãƒ¼ã§ã‚¢ã‚¦ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒ åŠ ç‚¹ | **ç›¸å¯¾å¼·åº¦ (RS)**<br>å¯¾ã‚»ã‚¯ã‚¿ãƒ¼ã§ã‚¢ã‚¦ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒ åŠ ç‚¹ | **ãƒªã‚¹ã‚¯ç®¡ç† (30%)**<br>ä½ãƒ™ãƒ¼ã‚¿ã€æ©Ÿé–¢ä¿æœ‰ç‡ã€æ¥­ç¸¾ |

            ---
            #### ç”¨èªè§£èª¬
            - **RVOL (Relative Volume)**: éå»å¹³å‡ã«å¯¾ã™ã‚‹å½“æ—¥ã®å‡ºæ¥é«˜å€ç‡ã€‚2å€ä»¥ä¸Šã¯å¼·ã„è³‡é‡‘æµå…¥ã‚’ç¤ºå”†ã€‚
            - **BBã‚¹ã‚¯ã‚¤ãƒ¼ã‚º**: ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ã®å¹…ãŒåç¸®ã—ã¦ã„ã‚‹çŠ¶æ…‹ã€‚ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè“„ç©ã•ã‚Œã€æ¬¡ã®å¤§ããªå‹•ãã®å‰å…†ã¨ã•ã‚Œã‚‹ã€‚**3æ—¥ä»¥ä¸Šç¶™ç¶šã§ãƒœãƒ¼ãƒŠã‚¹åŠ ç‚¹ã€‚**
            - **ç›¸å¯¾å¼·åº¦ (RS)**: ã‚»ã‚¯ã‚¿ãƒ¼ETFã‚„å¸‚å ´å…¨ä½“ã¨æ¯”è¼ƒã—ãŸå¼·ã•ã€‚ã‚»ã‚¯ã‚¿ãƒ¼å¹³å‡ã‚’ä¸Šå›ã‚‹ï¼ˆã‚¢ã‚¦ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒ ï¼‰éŠ˜æŸ„ã‚’é«˜ãè©•ä¾¡ã€‚
            
            """)
        



    
    # ==========================================
    # ğŸ” Momentum Analyzer (Deep Dive)
    # ==========================================
    # --- Momentum Analyzer Tab ---
    # With tab removed, this is now a top-level section
    
    # st.markdown("---") # Already present in previous context potentially, but let's ensure structure
    st.subheader("ğŸ” å€‹åˆ¥éŠ˜æŸ„è©³ç´°åˆ†æ & å£²è²·ã‚·ã‚°ãƒŠãƒ«")
    st.caption("å€‹åˆ¥éŠ˜æŸ„ã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ çŠ¶æ…‹ã‚’è©³ç´°åˆ†æã—ã€éå»ã®ãƒãƒ£ãƒ¼ãƒˆã‹ã‚‰AIãŒå£²è²·åˆ¤æ–­ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’æç¤ºã—ã¾ã™ã€‚")
    
    col_input, col_btn = st.columns([3, 1])
    with col_input:
        analyzer_ticker = st.text_input("ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ã‚’å…¥åŠ› (ä¾‹: NVDA, 7203.T)", value="NVDA").upper()
    with col_btn:
        st.write("") # Spacer
        run_analysis = st.button("è©³ç´°åˆ†æã‚’å®Ÿè¡Œ", type="primary")
        
    if run_analysis and analyzer_ticker:
        with st.spinner(f"{analyzer_ticker} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»åˆ†æä¸­..."):
            # Call Logic
            df_hist, summary = market_logic.analyze_stock_history(analyzer_ticker)
            
            if df_hist is None:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {summary.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ')}")
            else:
                # --- 1. Status Badge & Action ---
                status = summary['status']
                action = summary['action']
                score = summary.get('score', 0)
                
                # Color mapping
                status_color = "#888"
                if status == "BUY": status_color = "#00CC00" # Green
                elif status == "HOLD": status_color = "#00AAFF" # BIue
                elif status == "SELL": status_color = "#FF4444" # Red
                elif status == "WAIT": status_color = "#FFA500" # Orange
                
                # Status Details with New Indicators
                st.markdown(f"""
                <div style="background: rgba(255,255,255,0.05); padding: 15px; border-radius: 10px; border-left: 5px solid {status_color}; margin-bottom: 20px;">
                    <div style="display:flex; align-items:center; gap: 15px;">
                        <span style="font-size: 2rem; font-weight: 900; color: {status_color};">{status}</span>
                        <div style="flex-grow: 1;">
                            <div style="font-size: 1.2rem; font-weight: bold;">{action}</div>
                            <div style="font-size: 0.8rem; color: #ccc;">
                                ç¾åœ¨å€¤: ${summary['price']:.2f} | RSI: {summary['rsi']:.1f} | MFI: {summary['mfi']:.1f}<br>
                                RVOL: {summary['rvol']:.2f}å€ | MACDã‚·ã‚°ãƒŠãƒ«: {"Bullish (ä¸Šæ˜‡)" if summary['macd'] > 0 else "Bearish (ä¸‹è½)"}<br>
                                <b>æåˆ‡ãƒ©ã‚¤ãƒ³(Chandelier): ${summary['chandelier']:.2f}</b>
                            </div>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # --- Signal Explanation (Updated) ---
                with st.expander("â„¹ï¸ æ–°ãƒ»ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šåŸºæº–ã¨æŒ‡æ¨™è§£èª¬"):
                    st.markdown("""
                    **ğŸ¯ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ (Buy)**
                    - **æ¡ä»¶**: [ãƒãƒ³ãƒ‰æ‹¡å¤§/é«˜å€¤æ›´æ–°] + [RVOL>1.5] + [MACDå¥½è»¢] + **[ADX>25]**
                    - **æ„å‘³**: ã€Œå‹¢ã„(Momentum)ã€ã¨ã€Œã‚¨ãƒãƒ«ã‚®ãƒ¼(Expansion)ã€ã«åŠ ãˆã€**ã€Œæ˜ç¢ºãªãƒˆãƒ¬ãƒ³ãƒ‰ç™ºç”Ÿ(ADX)ã€** ã‚’ç¢ºèªã—ã¾ã™ã€‚
                    - **åˆ¶é™**: è²·ã„å¢—ã—éç†±é˜²æ­¢ã®ãŸã‚ã€**1ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ãæœ€å¤§3å›ã¾ã§** ã¨ã—ã€ã‹ã¤ **5æ—¥é–“ã®é–“éš”** ã‚’ç©ºã‘ã¾ã™ã€‚
                    - **ä¾‹å¤–**: å¤§é™½ç·šã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›(Reversal)ã‚„ã€æ˜ç¢ºãªæŠ¼ã—ç›®(Re-entry)ã¯åˆ¥é€”åˆ¤å®šã—ã¾ã™ã€‚
                    
                    **ğŸ‘‹ ã‚¨ã‚°ã‚¸ãƒƒãƒˆ (Sell/Profit Take/Stop)**
                    - **æ¡ä»¶**: ãƒã‚¸ã‚·ãƒ§ãƒ³ä¿æœ‰ä¸­ï¼ˆBuyç™ºç”Ÿå¾Œï¼‰ã®ã¿ã‚·ã‚°ãƒŠãƒ«ã‚’ç›£è¦–ã—ã¾ã™ã€‚ãƒãƒ¼ãƒã‚¸è¿·å­ï¼ˆPhantom Sellï¼‰ã¯é˜²ãã¾ã™ã€‚
                    - **åˆ©ç¢º (Profit)**: **RSI > 90** ã¾ãŸã¯ MACDãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹(â€»éç†±å¾Œã®ã¿)ã€‚é€ƒã’é…ã‚Œé˜²æ­¢(RSI<60å‰²ã‚Œ)ã‚‚å®Œå‚™ã€‚
                    - **æåˆ‡ (Stop)**: **Chandelier Exit** ã‚’ä¸‹å›ã£ãŸã‚‰å³æ’¤é€€ã€‚æ˜ç¢ºãªãƒˆãƒ¬ãƒ³ãƒ‰çµ‚äº†ã‚µã‚¤ãƒ³ã§ã™ã€‚
                    
                    **ğŸ“‰ Chandelier Exit (ã‚·ãƒ£ãƒ³ãƒ‡ãƒªã‚¢ãƒ»ã‚¤ã‚°ã‚¸ãƒƒãƒˆ)**
                    - ãƒãƒ£ãƒ¼ãƒˆä¸Šã® **ç´«è‰²ã®ç‚¹ç·š** ã§ã™ã€‚æŒ¯ã‚‹ã„è½ã¨ã—ã‚’é˜²ããŸã‚ã€**ATRÃ—5.0** ã®åºƒã‚ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚
                    - æ ªä¾¡ãŒã“ã‚Œã‚’å‰²ã‚Šè¾¼ã‚“ã ã‚‰ã€ãƒˆãƒ¬ãƒ³ãƒ‰å®Œå…¨çµ‚äº†ã¨ã¿ãªã—ã¦æ’¤é€€ã—ã¦ãã ã•ã„ã€‚
                    """)
                
                # --- 2. Interactive Chart (Plotly) ---
                # Title outside chart to prevent overlap
                st.markdown(f"##### ğŸ“ˆ {analyzer_ticker} å¼·åŒ–ç‰ˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒãƒ£ãƒ¼ãƒˆ")
                
                # Candlestick
                fig = go.Figure(data=[go.Candlestick(x=df_hist.index,
                                open=df_hist['Open'],
                                high=df_hist['High'],
                                low=df_hist['Low'],
                                close=df_hist['Close'],
                                name='æ ªä¾¡')])
                
                # SMAs
                fig.add_trace(go.Scatter(x=df_hist.index, y=df_hist['SMA50'], line=dict(color='#FFA500', width=1), name='SMA50 (ä¸­æœŸ)'))
                fig.add_trace(go.Scatter(x=df_hist.index, y=df_hist['SMA150'], line=dict(color='green', width=1), name='SMA150'))
                
                # Chandelier Exit (Trailing Stop)
                fig.add_trace(go.Scatter(x=df_hist.index, y=df_hist['Chandelier_Exit'], 
                                         line=dict(color='violet', width=1.5, dash='dot'), 
                                         name='Chandelier Exit (æåˆ‡ãƒ©ã‚¤ãƒ³)'))
                
                # BB
                fig.add_trace(go.Scatter(x=df_hist.index, y=df_hist['BB_Upper'], line=dict(color='gray', width=0), showlegend=False))
                fig.add_trace(go.Scatter(x=df_hist.index, y=df_hist['BB_Lower'], line=dict(color='gray', width=0), fill='tonexty', fillcolor='rgba(128,128,128,0.1)', showlegend=False, name='BB'))
                
                # Buy/Sell Markers
                signals = df_hist[df_hist['Signal'].notna()]
                
                for date, row in signals.iterrows():
                    sig = row['Signal']
                    reason = row['Reason']
                    
                    marker_color = "#00CC00" 
                    # Use B/S text instead of simple arrow-only or long text
                    symbol_text = "B" 
                    bgcolor = "#00CC00"
                    offset = 20
                    y_anchor = row['Low']
                    ay = 25 # Arrow length
                    
                    if sig == "Sell":
                        marker_color = "#FF4444"
                        symbol_text = "S"
                        bgcolor = "#FF4444"
                        offset = -20
                        y_anchor = row['High']
                        ay = -25
                        
                    # Detailed Hover Text
                    hover_text = f"<b>{sig} Signal</b><br>{reason}<br>Price: ${row['Close']:.2f}"
                    
                    fig.add_annotation(
                        x=date, y=y_anchor,
                        text=symbol_text,
                        showarrow=True,
                        arrowhead=1, # Simpler arrowhead
                        arrowsize=0.8, # Smaller head
                        arrowwidth=1.0, # Thinner line
                        arrowcolor=marker_color,
                        ax=0,
                        ay=ay * 0.6, # Shorter arrow (was 25, now ~15)
                        bgcolor=bgcolor,
                        bordercolor="#ffffff",
                        borderwidth=1,
                        borderpad=1, # Tighter box
                        opacity=0.8,
                        font=dict(color="white", size=8, weight="bold"), # Smaller font
                        hovertext=hover_text
                    )

                fig.update_layout(
                    # Title Removed from here to avoid overlap
                    yaxis_title="", 
                    yaxis_side="right", # Move price axis to right (TradingView style)
                    xaxis_title="",
                    xaxis_rangeslider_visible=False,
                    height=450, # Slightly Taller
                    margin=dict(l=0, r=10, t=10, b=40), # Left margin 0, Small right margin for axis
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)',
                    font=dict(color='white'),
                    showlegend=True,
                    legend=dict(
                        orientation="h",
                        yanchor="top", y=-0.1, # Position below chart
                        xanchor="center", x=0.5, # Center horizontally
                        font=dict(size=10),
                        bgcolor="rgba(0,0,0,0)"
                    ),
                    dragmode='pan'
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # --- 3. Alternatives ---
                st.markdown("#### ğŸ’¡ åŒã‚»ã‚¯ã‚¿ãƒ¼ã®æœ‰æœ›éŠ˜æŸ„ï¼ˆBuyå€™è£œï¼‰")
                st.caption(f"å…¥åŠ›ã•ã‚ŒãŸéŠ˜æŸ„ ({analyzer_ticker}) ã¨åŒã˜ã‚»ã‚¯ã‚¿ãƒ¼ã§ã€**ç¾åœ¨Buyã‚·ã‚°ãƒŠãƒ«ç‚¹ç¯ä¸­ã¾ãŸã¯å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰**ã«ã‚ã‚‹é«˜ã‚¹ã‚³ã‚¢éŠ˜æŸ„ã‚’ææ¡ˆã—ã¾ã™ã€‚")
                
                alternatives = market_logic.find_better_alternatives(analyzer_ticker, df_metrics)
                
                if alternatives:
                    cols = st.columns(3)
                    for i, alt in enumerate(alternatives):
                        with cols[i % 3]:
                            st.markdown(f"""
                            <div style="border:1px solid #444; padding:10px; border-radius:5px; text-align:center;">
                                <div style="color:#4ECDC4; font-weight:bold;">{alt['Ticker']}</div>
                                <div style="font-size:0.8rem;">ç·åˆã‚¹ã‚³ã‚¢: {alt['Score']:.1f}</div>
                                <div style="font-size:0.7rem; color:#aaa;">RVOL: {alt['RVOL']:.1f}å€ | 1ãƒ¶æœˆ: {alt['1mo']:+.1f}%</div>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã«ã€ã‚ˆã‚Šæœ‰æœ›ãªï¼ˆBuyæ¡ä»¶ã‚’æº€ãŸã™ï¼‰åŒã‚»ã‚¯ã‚¿ãƒ¼éŠ˜æŸ„ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ==========================================
    # ğŸ¤– AI Portfolio Builder (Alpha) - Collapsible
    # ==========================================
    st.markdown("---")
    
    # Generate Portfolios Logic (Moved from Top)
    # Need correlation matrix for Bento Box
    with st.spinner("Calculating portfolio correlations..."):
        try:
             price_history_df = pd.DataFrame(history_dict)
             corr_matrix = price_history_df.corr()
             if corr_matrix.empty:
                 corr_matrix = pd.DataFrame()
        except Exception as e:
            corr_matrix = pd.DataFrame()

    # Identify Short-term Losers
    exclude_list = set()
    try:
        if '1d' in df_metrics.columns:
            worst_1d = df_metrics.sort_values('1d', ascending=True).head(10)['Ticker'].tolist()
            exclude_list.update(worst_1d)
        if '5d' in df_metrics.columns:
            worst_5d = df_metrics.sort_values('5d', ascending=True).head(10)['Ticker'].tolist()
            exclude_list.update(worst_5d)
    except:
        pass 

    ai_portfolios = generate_ai_portfolios(df_sorted, corr_matrix, exclude_tickers=exclude_list)
    
    with st.expander("ğŸ¤– AI Portfolio Builder (Alpha) - ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹", expanded=False):
        st.caption("ç¾åœ¨ã®å¸‚å ´ç’°å¢ƒï¼ˆMomentum/Trend/Correlationï¼‰ã«åŸºã¥ãã€AIãŒæ¨å¥¨ã™ã‚‹3ã¤ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ¡ˆã§ã™ã€‚")
        
        def render_portfolio_tab(name, df, emoji, desc):
            if df.empty:
                st.warning("æ¡ä»¶ã«åˆè‡´ã™ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
                
            col1, col2 = st.columns([1.5, 1])
            
            with col1:
                st.markdown(f"### {emoji} {name}")
                st.caption(desc)
                
                # Display Table
                display_cols = ['Ticker', 'Price', '1mo', '3mo', 'RVOL', 'RSI', 'Signal']
                # Ensure cols exist
                valid_cols = [c for c in display_cols if c in df.columns]
                st.dataframe(df[valid_cols].style.format({
                    'Price': "{:.2f}",
                    '1mo': "{:+.2f}%",
                    '3mo': "{:+.2f}%",
                    'RVOL': "{:.2f}",
                    'RSI': "{:.1f}"
                }), hide_index=True)
                
                # Virtual Performance
                sim_return = calculate_simulated_return(df)
                st.metric("ğŸ“Š éå»1ãƒ¶æœˆã®ä»®æƒ³ãƒªã‚¿ãƒ¼ãƒ³ (ç›´è¿‘å®Ÿç¸¾)", f"{sim_return:+.2f}%")
                
            with col2:
                # Pie Chart
                # Equal weight for now
                df['Weight'] = 100 / len(df)
                fig = px.pie(df, values='Weight', names='Ticker', title=f"{name} Allocation", hole=0.4)
                st.plotly_chart(fig, use_container_width=True)

        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ The Hunter", "ğŸ¦… The Sniper", "ğŸ° The Fortress", "ğŸ¥— The Bento Box"])
        
        with tab1:
            render_portfolio_tab("The Hunter (çŸ­æœŸé›†ä¸­)", ai_portfolios['Hunter'], "ğŸ¯", 
                                 "**æ”»æ’ƒå‹:** ãƒªã‚¿ãƒ¼ãƒ³ãƒ»å‡ºæ¥é«˜é‡è¦–ã€‚åŠ ç†±æ„Ÿï¼ˆRSIé«˜ï¼‰ã‚’å•ã‚ãšã€ã¨ã«ã‹ãã€Œä»Šå¼·ã„ã€éŠ˜æŸ„ã«ä¹—ã‚‹æˆ¦ç•¥ã€‚â€»é«˜å€¤æ´ã¿æ³¨æ„")
            
        with tab2:
            render_portfolio_tab("The Sniper (ç²¾å¯†å°„æ’ƒ)", ai_portfolios['Sniper'], "ğŸ¦…", 
                                 "**å³é¸å‹:** Hunterã¨åŒæ§˜ã«å¼·ã„ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’æŒã¡ã¤ã¤ã€RSI < 70 ã®ã€Œã¾ã åŠ ç†±ã—ã¦ã„ãªã„ã€éŠ˜æŸ„ã«çµã£ãŸæˆ¦ç•¥ã€‚å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³é‡è¦–ã€‚")
                                 
        with tab3:
            render_portfolio_tab("The Fortress (å …å®Ÿãƒˆãƒ¬ãƒ³ãƒ‰)", ai_portfolios['Fortress'], "ğŸ°",
                                 "**é †å¼µã‚Šå‹:** 3ãƒ¶æœˆã€6ãƒ¶æœˆã€å¹´åˆæ¥ãŒã™ã¹ã¦ãƒ—ãƒ©ã‚¹ã®ã€Œè² ã‘ãªã„ã€ãƒˆãƒ¬ãƒ³ãƒ‰éŠ˜æŸ„ã€‚å®‰å®šã—ãŸä¸Šæ˜‡æ°—æµã«ä¹—ã‚‹ãŸã‚ã®æ§‹æˆã€‚")
            
        with tab4:
            render_portfolio_tab("The Bento Box (ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ•£)", ai_portfolios['Bento'], "ğŸ¥—",
                                 "**ãƒãƒ©ãƒ³ã‚¹å‹:** ä¸»è¦ãƒ†ãƒ¼ãƒï¼ˆAIãƒ»ã‚¨ãƒãƒ»é‡‘èãƒ»å®‡å®™ãƒ»æ¶ˆè²»ï¼‰ã‹ã‚‰ãã‚Œãã‚Œæœ€å¼·ã®1éŠ˜æŸ„ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€‚ç›¸é–¢ä¿‚æ•°ã‚’æŠ‘ãˆã¤ã¤ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç‹™ã†å¹•ã®å†…å¼å½“ã€‚")
                            
    # --- Footer: Disclaimer ---

    st.markdown("---")
    st.caption("âš ï¸ **å…è²¬äº‹é …**: æœ¬ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡å‹§èª˜ã‚„åŠ©è¨€ã‚’æ„å›³ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è¡¨ç¤ºã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„AIã«ã‚ˆã‚‹åˆ†æçµæœã¯éå»ã®å®Ÿç¸¾ã«åŸºã¥ã„ã¦ãŠã‚Šã€å°†æ¥ã®é‹ç”¨æˆæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã«ãŠã„ã¦è¡Œã£ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
